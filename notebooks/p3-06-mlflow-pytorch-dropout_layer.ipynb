{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "225b4513-9c5c-4a26-92f7-a8fde12373fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import mlflow.pytorch\n",
    "import numpy as np\n",
    "\n",
    "import mlflow\n",
    "\n",
    "import os\n",
    "import sys\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))  # Adjust to your project's structure\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from src.analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ebbbf6b-7a6e-4adc-9542-a6ab2b8d59da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set MLFlow tracking URI (local or server-based)\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")  # Change if using a centralized server\n",
    "\n",
    "# Define the experiment name\n",
    "mlflow.set_experiment(\"MVP Prediction NN\")\n",
    "\n",
    "mlflow.set_tag(\"developer\", \"christophe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "539ebad6-26fa-4517-adcf-5ff79a4d2ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: torch.Size([206, 184]) torch.Size([206])\n",
      "Validation set: torch.Size([44, 184]) torch.Size([44])\n",
      "Test set: torch.Size([45, 184]) torch.Size([45])\n"
     ]
    }
   ],
   "source": [
    "# Load your cleaned dataset\n",
    "data_path = \"/Users/cb/src/nba_mvp_ml/data/processed/by_season/fully_merged/final_stacked_data.csv\"\n",
    "\n",
    "_X, _y = load_and_preprocess_data(data_path, remove_excess_features=False) # X will be normalized\n",
    "\n",
    "\n",
    "# Example input data\n",
    "np.random.seed(42)\n",
    "X =_X.to_numpy().astype(np.float32)\n",
    "y = _y.to_numpy().astype(np.int64)  # Binary labels\n",
    "\n",
    "# Determine sizes for train, validation, and test splits\n",
    "train_size = int(0.7 * len(X))  # 70% for training\n",
    "val_size = int(0.15 * len(X))   # 15% for validation\n",
    "test_size = len(X) - train_size - val_size  # Remaining 15% for testing\n",
    "\n",
    "# Split the datase\n",
    "X_train = torch.tensor(X[:train_size])\n",
    "y_train = torch.tensor(y[:train_size])\n",
    "\n",
    "X_val= torch.tensor(X[train_size:train_size + val_size])\n",
    "y_val= torch.tensor(y[train_size:train_size + val_size])\n",
    "\n",
    "X_test = torch.tensor(X[train_size + val_size:])\n",
    "y_test = torch.tensor(y[train_size + val_size:])\n",
    "\n",
    "_y_test = _y[train_size + val_size:]\n",
    "\n",
    "# Check the shapes of each split\n",
    "print(\"Train set:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set:\", X_val.shape, y_val.shape)\n",
    "print(\"Test set:\", X_test.shape, y_test.shape)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 32\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a7524d4-b75b-4fd1-bfc6-d843699be433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define a simple neural network\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.dropout = nn.Dropout(p=0.5)  # Dropout with 50% rate\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)  # Apply dropout\n",
    "        x = self.fc2(x)\n",
    "        return self.softmax(x)\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = len(_X.columns)\n",
    "hidden_size = 64\n",
    "output_size = 2\n",
    "learning_rate = 0.001\n",
    "num_epochs = 200\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = SimpleMLP(input_size, hidden_size, output_size).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16d94e08-db76-4720-be73-ea73f9cc08c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Loss: 0.7031\n",
      "Validation Loss: 0.6406, Accuracy: 75.00%\n",
      "Epoch [2/200], Loss: 0.6054\n",
      "Validation Loss: 0.5631, Accuracy: 86.36%\n",
      "Epoch [3/200], Loss: 0.5455\n",
      "Validation Loss: 0.5115, Accuracy: 84.09%\n",
      "Epoch [4/200], Loss: 0.5075\n",
      "Validation Loss: 0.4794, Accuracy: 84.09%\n",
      "Epoch [5/200], Loss: 0.4887\n",
      "Validation Loss: 0.4610, Accuracy: 84.09%\n",
      "Epoch [6/200], Loss: 0.4794\n",
      "Validation Loss: 0.4499, Accuracy: 84.09%\n",
      "Epoch [7/200], Loss: 0.4493\n",
      "Validation Loss: 0.4422, Accuracy: 86.36%\n",
      "Epoch [8/200], Loss: 0.4426\n",
      "Validation Loss: 0.4353, Accuracy: 86.36%\n",
      "Epoch [9/200], Loss: 0.4315\n",
      "Validation Loss: 0.4287, Accuracy: 86.36%\n",
      "Epoch [10/200], Loss: 0.4177\n",
      "Validation Loss: 0.4232, Accuracy: 86.36%\n",
      "Epoch [11/200], Loss: 0.4326\n",
      "Validation Loss: 0.4201, Accuracy: 86.36%\n",
      "Epoch [12/200], Loss: 0.4239\n",
      "Validation Loss: 0.4168, Accuracy: 86.36%\n",
      "Epoch [13/200], Loss: 0.4273\n",
      "Validation Loss: 0.4147, Accuracy: 86.36%\n",
      "Epoch [14/200], Loss: 0.4101\n",
      "Validation Loss: 0.4096, Accuracy: 90.91%\n",
      "Epoch [15/200], Loss: 0.4044\n",
      "Validation Loss: 0.4065, Accuracy: 90.91%\n",
      "Epoch [16/200], Loss: 0.3985\n",
      "Validation Loss: 0.4050, Accuracy: 93.18%\n",
      "Epoch [17/200], Loss: 0.4030\n",
      "Validation Loss: 0.4024, Accuracy: 90.91%\n",
      "Epoch [18/200], Loss: 0.3970\n",
      "Validation Loss: 0.3966, Accuracy: 93.18%\n",
      "Epoch [19/200], Loss: 0.3893\n",
      "Validation Loss: 0.3942, Accuracy: 90.91%\n",
      "Epoch [20/200], Loss: 0.3881\n",
      "Validation Loss: 0.3924, Accuracy: 90.91%\n",
      "Epoch [21/200], Loss: 0.3864\n",
      "Validation Loss: 0.3909, Accuracy: 90.91%\n",
      "Epoch [22/200], Loss: 0.3922\n",
      "Validation Loss: 0.3851, Accuracy: 93.18%\n",
      "Epoch [23/200], Loss: 0.3781\n",
      "Validation Loss: 0.3835, Accuracy: 93.18%\n",
      "Epoch [24/200], Loss: 0.3668\n",
      "Validation Loss: 0.3816, Accuracy: 93.18%\n",
      "Epoch [25/200], Loss: 0.3789\n",
      "Validation Loss: 0.3787, Accuracy: 93.18%\n",
      "Epoch [26/200], Loss: 0.3827\n",
      "Validation Loss: 0.3755, Accuracy: 93.18%\n",
      "Epoch [27/200], Loss: 0.3787\n",
      "Validation Loss: 0.3744, Accuracy: 93.18%\n",
      "Epoch [28/200], Loss: 0.3763\n",
      "Validation Loss: 0.3716, Accuracy: 93.18%\n",
      "Epoch [29/200], Loss: 0.3762\n",
      "Validation Loss: 0.3689, Accuracy: 93.18%\n",
      "Epoch [30/200], Loss: 0.3730\n",
      "Validation Loss: 0.3663, Accuracy: 93.18%\n",
      "Epoch [31/200], Loss: 0.3735\n",
      "Validation Loss: 0.3644, Accuracy: 95.45%\n",
      "Epoch [32/200], Loss: 0.3704\n",
      "Validation Loss: 0.3645, Accuracy: 95.45%\n",
      "Epoch [33/200], Loss: 0.3617\n",
      "Validation Loss: 0.3646, Accuracy: 95.45%\n",
      "Epoch [34/200], Loss: 0.3676\n",
      "Validation Loss: 0.3646, Accuracy: 93.18%\n",
      "Epoch [35/200], Loss: 0.3613\n",
      "Validation Loss: 0.3639, Accuracy: 93.18%\n",
      "Epoch [36/200], Loss: 0.3746\n",
      "Validation Loss: 0.3620, Accuracy: 93.18%\n",
      "Epoch [37/200], Loss: 0.3581\n",
      "Validation Loss: 0.3616, Accuracy: 95.45%\n",
      "Epoch [38/200], Loss: 0.3638\n",
      "Validation Loss: 0.3597, Accuracy: 95.45%\n",
      "Epoch [39/200], Loss: 0.3557\n",
      "Validation Loss: 0.3570, Accuracy: 97.73%\n",
      "Epoch [40/200], Loss: 0.3462\n",
      "Validation Loss: 0.3549, Accuracy: 97.73%\n",
      "Epoch [41/200], Loss: 0.3588\n",
      "Validation Loss: 0.3550, Accuracy: 95.45%\n",
      "Epoch [42/200], Loss: 0.3506\n",
      "Validation Loss: 0.3570, Accuracy: 95.45%\n",
      "Epoch [43/200], Loss: 0.3543\n",
      "Validation Loss: 0.3581, Accuracy: 93.18%\n",
      "Epoch [44/200], Loss: 0.3467\n",
      "Validation Loss: 0.3595, Accuracy: 95.45%\n",
      "Epoch [45/200], Loss: 0.3424\n",
      "Validation Loss: 0.3593, Accuracy: 95.45%\n",
      "Epoch [46/200], Loss: 0.3506\n",
      "Validation Loss: 0.3581, Accuracy: 95.45%\n",
      "Epoch [47/200], Loss: 0.3421\n",
      "Validation Loss: 0.3561, Accuracy: 95.45%\n",
      "Epoch [48/200], Loss: 0.3483\n",
      "Validation Loss: 0.3563, Accuracy: 95.45%\n",
      "Epoch [49/200], Loss: 0.3474\n",
      "Validation Loss: 0.3555, Accuracy: 95.45%\n",
      "Epoch [50/200], Loss: 0.3441\n",
      "Validation Loss: 0.3542, Accuracy: 95.45%\n",
      "Epoch [51/200], Loss: 0.3526\n",
      "Validation Loss: 0.3542, Accuracy: 95.45%\n",
      "Epoch [52/200], Loss: 0.3455\n",
      "Validation Loss: 0.3554, Accuracy: 93.18%\n",
      "Epoch [53/200], Loss: 0.3475\n",
      "Validation Loss: 0.3533, Accuracy: 93.18%\n",
      "Epoch [54/200], Loss: 0.3536\n",
      "Validation Loss: 0.3511, Accuracy: 95.45%\n",
      "Epoch [55/200], Loss: 0.3399\n",
      "Validation Loss: 0.3497, Accuracy: 95.45%\n",
      "Epoch [56/200], Loss: 0.3414\n",
      "Validation Loss: 0.3490, Accuracy: 95.45%\n",
      "Epoch [57/200], Loss: 0.3407\n",
      "Validation Loss: 0.3502, Accuracy: 95.45%\n",
      "Epoch [58/200], Loss: 0.3364\n",
      "Validation Loss: 0.3530, Accuracy: 95.45%\n",
      "Epoch [59/200], Loss: 0.3332\n",
      "Validation Loss: 0.3527, Accuracy: 95.45%\n",
      "Epoch [60/200], Loss: 0.3389\n",
      "Validation Loss: 0.3520, Accuracy: 95.45%\n",
      "Epoch [61/200], Loss: 0.3306\n",
      "Validation Loss: 0.3522, Accuracy: 95.45%\n",
      "Epoch [62/200], Loss: 0.3464\n",
      "Validation Loss: 0.3516, Accuracy: 95.45%\n",
      "Epoch [63/200], Loss: 0.3298\n",
      "Validation Loss: 0.3509, Accuracy: 95.45%\n",
      "Epoch [64/200], Loss: 0.3328\n",
      "Validation Loss: 0.3507, Accuracy: 95.45%\n",
      "Epoch [65/200], Loss: 0.3349\n",
      "Validation Loss: 0.3498, Accuracy: 95.45%\n",
      "Epoch [66/200], Loss: 0.3404\n",
      "Validation Loss: 0.3497, Accuracy: 95.45%\n",
      "Epoch [67/200], Loss: 0.3385\n",
      "Validation Loss: 0.3507, Accuracy: 95.45%\n",
      "Epoch [68/200], Loss: 0.3316\n",
      "Validation Loss: 0.3507, Accuracy: 95.45%\n",
      "Epoch [69/200], Loss: 0.3358\n",
      "Validation Loss: 0.3493, Accuracy: 95.45%\n",
      "Epoch [70/200], Loss: 0.3286\n",
      "Validation Loss: 0.3474, Accuracy: 95.45%\n",
      "Epoch [71/200], Loss: 0.3321\n",
      "Validation Loss: 0.3477, Accuracy: 95.45%\n",
      "Epoch [72/200], Loss: 0.3317\n",
      "Validation Loss: 0.3501, Accuracy: 95.45%\n",
      "Epoch [73/200], Loss: 0.3346\n",
      "Validation Loss: 0.3521, Accuracy: 95.45%\n",
      "Epoch [74/200], Loss: 0.3353\n",
      "Validation Loss: 0.3539, Accuracy: 93.18%\n",
      "Epoch [75/200], Loss: 0.3342\n",
      "Validation Loss: 0.3542, Accuracy: 93.18%\n",
      "Epoch [76/200], Loss: 0.3286\n",
      "Validation Loss: 0.3505, Accuracy: 95.45%\n",
      "Epoch [77/200], Loss: 0.3324\n",
      "Validation Loss: 0.3488, Accuracy: 95.45%\n",
      "Epoch [78/200], Loss: 0.3338\n",
      "Validation Loss: 0.3484, Accuracy: 95.45%\n",
      "Epoch [79/200], Loss: 0.3314\n",
      "Validation Loss: 0.3474, Accuracy: 95.45%\n",
      "Epoch [80/200], Loss: 0.3307\n",
      "Validation Loss: 0.3490, Accuracy: 95.45%\n",
      "Epoch [81/200], Loss: 0.3307\n",
      "Validation Loss: 0.3519, Accuracy: 95.45%\n",
      "Epoch [82/200], Loss: 0.3289\n",
      "Validation Loss: 0.3539, Accuracy: 93.18%\n",
      "Epoch [83/200], Loss: 0.3255\n",
      "Validation Loss: 0.3535, Accuracy: 93.18%\n",
      "Epoch [84/200], Loss: 0.3400\n",
      "Validation Loss: 0.3523, Accuracy: 95.45%\n",
      "Epoch [85/200], Loss: 0.3234\n",
      "Validation Loss: 0.3510, Accuracy: 95.45%\n",
      "Epoch [86/200], Loss: 0.3270\n",
      "Validation Loss: 0.3501, Accuracy: 95.45%\n",
      "Epoch [87/200], Loss: 0.3271\n",
      "Validation Loss: 0.3494, Accuracy: 95.45%\n",
      "Epoch [88/200], Loss: 0.3320\n",
      "Validation Loss: 0.3492, Accuracy: 95.45%\n",
      "Epoch [89/200], Loss: 0.3301\n",
      "Validation Loss: 0.3501, Accuracy: 95.45%\n",
      "Epoch [90/200], Loss: 0.3338\n",
      "Validation Loss: 0.3506, Accuracy: 95.45%\n",
      "Epoch [91/200], Loss: 0.3258\n",
      "Validation Loss: 0.3534, Accuracy: 93.18%\n",
      "Epoch [92/200], Loss: 0.3308\n",
      "Validation Loss: 0.3518, Accuracy: 93.18%\n",
      "Epoch [93/200], Loss: 0.3276\n",
      "Validation Loss: 0.3492, Accuracy: 95.45%\n",
      "Epoch [94/200], Loss: 0.3251\n",
      "Validation Loss: 0.3450, Accuracy: 95.45%\n",
      "Epoch [95/200], Loss: 0.3247\n",
      "Validation Loss: 0.3439, Accuracy: 95.45%\n",
      "Epoch [96/200], Loss: 0.3250\n",
      "Validation Loss: 0.3456, Accuracy: 95.45%\n",
      "Epoch [97/200], Loss: 0.3245\n",
      "Validation Loss: 0.3468, Accuracy: 95.45%\n",
      "Epoch [98/200], Loss: 0.3224\n",
      "Validation Loss: 0.3446, Accuracy: 95.45%\n",
      "Epoch [99/200], Loss: 0.3192\n",
      "Validation Loss: 0.3434, Accuracy: 95.45%\n",
      "Epoch [100/200], Loss: 0.3233\n",
      "Validation Loss: 0.3424, Accuracy: 95.45%\n",
      "Epoch [101/200], Loss: 0.3191\n",
      "Validation Loss: 0.3415, Accuracy: 95.45%\n",
      "Epoch [102/200], Loss: 0.3242\n",
      "Validation Loss: 0.3427, Accuracy: 95.45%\n",
      "Epoch [103/200], Loss: 0.3185\n",
      "Validation Loss: 0.3463, Accuracy: 93.18%\n",
      "Epoch [104/200], Loss: 0.3208\n",
      "Validation Loss: 0.3479, Accuracy: 93.18%\n",
      "Epoch [105/200], Loss: 0.3209\n",
      "Validation Loss: 0.3485, Accuracy: 93.18%\n",
      "Epoch [106/200], Loss: 0.3238\n",
      "Validation Loss: 0.3446, Accuracy: 93.18%\n",
      "Epoch [107/200], Loss: 0.3194\n",
      "Validation Loss: 0.3437, Accuracy: 93.18%\n",
      "Epoch [108/200], Loss: 0.3216\n",
      "Validation Loss: 0.3433, Accuracy: 95.45%\n",
      "Epoch [109/200], Loss: 0.3194\n",
      "Validation Loss: 0.3428, Accuracy: 95.45%\n",
      "Epoch [110/200], Loss: 0.3199\n",
      "Validation Loss: 0.3435, Accuracy: 95.45%\n",
      "Epoch [111/200], Loss: 0.3209\n",
      "Validation Loss: 0.3442, Accuracy: 95.45%\n",
      "Epoch [112/200], Loss: 0.3250\n",
      "Validation Loss: 0.3429, Accuracy: 95.45%\n",
      "Epoch [113/200], Loss: 0.3215\n",
      "Validation Loss: 0.3411, Accuracy: 95.45%\n",
      "Epoch [114/200], Loss: 0.3198\n",
      "Validation Loss: 0.3416, Accuracy: 95.45%\n",
      "Epoch [115/200], Loss: 0.3232\n",
      "Validation Loss: 0.3424, Accuracy: 95.45%\n",
      "Epoch [116/200], Loss: 0.3208\n",
      "Validation Loss: 0.3444, Accuracy: 95.45%\n",
      "Epoch [117/200], Loss: 0.3205\n",
      "Validation Loss: 0.3462, Accuracy: 95.45%\n",
      "Epoch [118/200], Loss: 0.3231\n",
      "Validation Loss: 0.3473, Accuracy: 95.45%\n",
      "Epoch [119/200], Loss: 0.3183\n",
      "Validation Loss: 0.3453, Accuracy: 95.45%\n",
      "Epoch [120/200], Loss: 0.3178\n",
      "Validation Loss: 0.3436, Accuracy: 95.45%\n",
      "Epoch [121/200], Loss: 0.3202\n",
      "Validation Loss: 0.3440, Accuracy: 95.45%\n",
      "Epoch [122/200], Loss: 0.3170\n",
      "Validation Loss: 0.3447, Accuracy: 95.45%\n",
      "Epoch [123/200], Loss: 0.3201\n",
      "Validation Loss: 0.3441, Accuracy: 95.45%\n",
      "Epoch [124/200], Loss: 0.3197\n",
      "Validation Loss: 0.3434, Accuracy: 95.45%\n",
      "Epoch [125/200], Loss: 0.3213\n",
      "Validation Loss: 0.3422, Accuracy: 95.45%\n",
      "Epoch [126/200], Loss: 0.3213\n",
      "Validation Loss: 0.3425, Accuracy: 95.45%\n",
      "Epoch [127/200], Loss: 0.3213\n",
      "Validation Loss: 0.3479, Accuracy: 93.18%\n",
      "Epoch [128/200], Loss: 0.3217\n",
      "Validation Loss: 0.3497, Accuracy: 93.18%\n",
      "Epoch [129/200], Loss: 0.3181\n",
      "Validation Loss: 0.3460, Accuracy: 95.45%\n",
      "Epoch [130/200], Loss: 0.3177\n",
      "Validation Loss: 0.3434, Accuracy: 95.45%\n",
      "Epoch [131/200], Loss: 0.3170\n",
      "Validation Loss: 0.3425, Accuracy: 95.45%\n",
      "Epoch [132/200], Loss: 0.3198\n",
      "Validation Loss: 0.3422, Accuracy: 95.45%\n",
      "Epoch [133/200], Loss: 0.3159\n",
      "Validation Loss: 0.3442, Accuracy: 95.45%\n",
      "Epoch [134/200], Loss: 0.3182\n",
      "Validation Loss: 0.3445, Accuracy: 95.45%\n",
      "Epoch [135/200], Loss: 0.3158\n",
      "Validation Loss: 0.3441, Accuracy: 95.45%\n",
      "Epoch [136/200], Loss: 0.3224\n",
      "Validation Loss: 0.3435, Accuracy: 95.45%\n",
      "Epoch [137/200], Loss: 0.3168\n",
      "Validation Loss: 0.3426, Accuracy: 95.45%\n",
      "Epoch [138/200], Loss: 0.3197\n",
      "Validation Loss: 0.3430, Accuracy: 95.45%\n",
      "Epoch [139/200], Loss: 0.3163\n",
      "Validation Loss: 0.3447, Accuracy: 95.45%\n",
      "Epoch [140/200], Loss: 0.3175\n",
      "Validation Loss: 0.3457, Accuracy: 95.45%\n",
      "Epoch [141/200], Loss: 0.3227\n",
      "Validation Loss: 0.3458, Accuracy: 95.45%\n",
      "Epoch [142/200], Loss: 0.3163\n",
      "Validation Loss: 0.3507, Accuracy: 93.18%\n",
      "Epoch [143/200], Loss: 0.3203\n",
      "Validation Loss: 0.3475, Accuracy: 93.18%\n",
      "Epoch [144/200], Loss: 0.3167\n",
      "Validation Loss: 0.3428, Accuracy: 95.45%\n",
      "Epoch [145/200], Loss: 0.3183\n",
      "Validation Loss: 0.3413, Accuracy: 97.73%\n",
      "Epoch [146/200], Loss: 0.3168\n",
      "Validation Loss: 0.3423, Accuracy: 95.45%\n",
      "Epoch [147/200], Loss: 0.3182\n",
      "Validation Loss: 0.3424, Accuracy: 95.45%\n",
      "Epoch [148/200], Loss: 0.3172\n",
      "Validation Loss: 0.3431, Accuracy: 93.18%\n",
      "Epoch [149/200], Loss: 0.3175\n",
      "Validation Loss: 0.3436, Accuracy: 93.18%\n",
      "Epoch [150/200], Loss: 0.3186\n",
      "Validation Loss: 0.3427, Accuracy: 95.45%\n",
      "Epoch [151/200], Loss: 0.3179\n",
      "Validation Loss: 0.3437, Accuracy: 95.45%\n",
      "Epoch [152/200], Loss: 0.3192\n",
      "Validation Loss: 0.3440, Accuracy: 95.45%\n",
      "Epoch [153/200], Loss: 0.3173\n",
      "Validation Loss: 0.3455, Accuracy: 95.45%\n",
      "Epoch [154/200], Loss: 0.3173\n",
      "Validation Loss: 0.3470, Accuracy: 95.45%\n",
      "Epoch [155/200], Loss: 0.3179\n",
      "Validation Loss: 0.3449, Accuracy: 95.45%\n",
      "Epoch [156/200], Loss: 0.3211\n",
      "Validation Loss: 0.3448, Accuracy: 95.45%\n",
      "Epoch [157/200], Loss: 0.3175\n",
      "Validation Loss: 0.3447, Accuracy: 93.18%\n",
      "Epoch [158/200], Loss: 0.3164\n",
      "Validation Loss: 0.3429, Accuracy: 95.45%\n",
      "Epoch [159/200], Loss: 0.3163\n",
      "Validation Loss: 0.3415, Accuracy: 95.45%\n",
      "Epoch [160/200], Loss: 0.3175\n",
      "Validation Loss: 0.3407, Accuracy: 95.45%\n",
      "Epoch [161/200], Loss: 0.3162\n",
      "Validation Loss: 0.3404, Accuracy: 95.45%\n",
      "Epoch [162/200], Loss: 0.3151\n",
      "Validation Loss: 0.3414, Accuracy: 95.45%\n",
      "Epoch [163/200], Loss: 0.3162\n",
      "Validation Loss: 0.3420, Accuracy: 95.45%\n",
      "Epoch [164/200], Loss: 0.3161\n",
      "Validation Loss: 0.3420, Accuracy: 95.45%\n",
      "Epoch [165/200], Loss: 0.3164\n",
      "Validation Loss: 0.3418, Accuracy: 95.45%\n",
      "Epoch [166/200], Loss: 0.3165\n",
      "Validation Loss: 0.3410, Accuracy: 95.45%\n",
      "Epoch [167/200], Loss: 0.3152\n",
      "Validation Loss: 0.3407, Accuracy: 95.45%\n",
      "Epoch [168/200], Loss: 0.3153\n",
      "Validation Loss: 0.3412, Accuracy: 95.45%\n",
      "Epoch [169/200], Loss: 0.3170\n",
      "Validation Loss: 0.3413, Accuracy: 95.45%\n",
      "Epoch [170/200], Loss: 0.3165\n",
      "Validation Loss: 0.3405, Accuracy: 95.45%\n",
      "Epoch [171/200], Loss: 0.3175\n",
      "Validation Loss: 0.3400, Accuracy: 95.45%\n",
      "Epoch [172/200], Loss: 0.3168\n",
      "Validation Loss: 0.3403, Accuracy: 95.45%\n",
      "Epoch [173/200], Loss: 0.3153\n",
      "Validation Loss: 0.3407, Accuracy: 95.45%\n",
      "Epoch [174/200], Loss: 0.3150\n",
      "Validation Loss: 0.3408, Accuracy: 95.45%\n",
      "Epoch [175/200], Loss: 0.3173\n",
      "Validation Loss: 0.3407, Accuracy: 95.45%\n",
      "Epoch [176/200], Loss: 0.3149\n",
      "Validation Loss: 0.3402, Accuracy: 95.45%\n",
      "Epoch [177/200], Loss: 0.3180\n",
      "Validation Loss: 0.3398, Accuracy: 95.45%\n",
      "Epoch [178/200], Loss: 0.3154\n",
      "Validation Loss: 0.3399, Accuracy: 95.45%\n",
      "Epoch [179/200], Loss: 0.3185\n",
      "Validation Loss: 0.3421, Accuracy: 95.45%\n",
      "Epoch [180/200], Loss: 0.3190\n",
      "Validation Loss: 0.3442, Accuracy: 95.45%\n",
      "Epoch [181/200], Loss: 0.3148\n",
      "Validation Loss: 0.3457, Accuracy: 95.45%\n",
      "Epoch [182/200], Loss: 0.3171\n",
      "Validation Loss: 0.3485, Accuracy: 93.18%\n",
      "Epoch [183/200], Loss: 0.3167\n",
      "Validation Loss: 0.3487, Accuracy: 93.18%\n",
      "Epoch [184/200], Loss: 0.3159\n",
      "Validation Loss: 0.3467, Accuracy: 93.18%\n",
      "Epoch [185/200], Loss: 0.3150\n",
      "Validation Loss: 0.3437, Accuracy: 95.45%\n",
      "Epoch [186/200], Loss: 0.3156\n",
      "Validation Loss: 0.3438, Accuracy: 95.45%\n",
      "Epoch [187/200], Loss: 0.3163\n",
      "Validation Loss: 0.3452, Accuracy: 95.45%\n",
      "Epoch [188/200], Loss: 0.3149\n",
      "Validation Loss: 0.3460, Accuracy: 95.45%\n",
      "Epoch [189/200], Loss: 0.3184\n",
      "Validation Loss: 0.3469, Accuracy: 95.45%\n",
      "Epoch [190/200], Loss: 0.3147\n",
      "Validation Loss: 0.3454, Accuracy: 95.45%\n",
      "Epoch [191/200], Loss: 0.3177\n",
      "Validation Loss: 0.3440, Accuracy: 95.45%\n",
      "Epoch [192/200], Loss: 0.3145\n",
      "Validation Loss: 0.3434, Accuracy: 95.45%\n",
      "Epoch [193/200], Loss: 0.3150\n",
      "Validation Loss: 0.3413, Accuracy: 95.45%\n",
      "Epoch [194/200], Loss: 0.3155\n",
      "Validation Loss: 0.3411, Accuracy: 95.45%\n",
      "Epoch [195/200], Loss: 0.3159\n",
      "Validation Loss: 0.3415, Accuracy: 95.45%\n",
      "Epoch [196/200], Loss: 0.3148\n",
      "Validation Loss: 0.3426, Accuracy: 95.45%\n",
      "Epoch [197/200], Loss: 0.3157\n",
      "Validation Loss: 0.3424, Accuracy: 95.45%\n",
      "Epoch [198/200], Loss: 0.3149\n",
      "Validation Loss: 0.3431, Accuracy: 95.45%\n",
      "Epoch [199/200], Loss: 0.3149\n",
      "Validation Loss: 0.3433, Accuracy: 95.45%\n",
      "Epoch [200/200], Loss: 0.3194\n",
      "Validation Loss: 0.3440, Accuracy: 95.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/05 20:24:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete and logged in MLflow.\n",
      "Precision: 0.6666666865348816\n",
      "Recall: 0.5714285969734192\n",
      "Accuracy: 0.8888888955116272\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(nested=True):\n",
    "    # Log hyperparameters\n",
    "    mlflow.log_param(\"input_size\", input_size)\n",
    "    mlflow.log_param(\"hidden_size\", hidden_size)\n",
    "    mlflow.log_param(\"output_size\", output_size)\n",
    "    mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "    mlflow.log_param(\"batch_size\", batch_size)\n",
    "    mlflow.log_param(\"num_epochs\", num_epochs)\n",
    "    mlflow.log_param(\"n_features\", len(_X.columns))\n",
    "\n",
    "    mlflow.log_param(\"model_name\", 'dropout')\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_train_loss:.4f}\")\n",
    "        mlflow.log_metric(\"train_loss\", avg_train_loss, step=epoch)\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == targets).sum().item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = 100 * correct / total\n",
    "        print(f\"Validation Loss: {avg_val_loss:.4f}, Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "        mlflow.log_metric(\"val_loss\", avg_val_loss, step=epoch)\n",
    "        mlflow.log_metric(\"val_accuracy\", val_accuracy, step=epoch)\n",
    "\n",
    "    # Log the trained model\n",
    "    mlflow.pytorch.log_model(model, \"model\")\n",
    "\n",
    "    print(\"Model training complete and logged in MLflow.\")\n",
    "\n",
    "\n",
    "    # TEST PERFORMANCE ALANYSIS ------------------------------------------------------------------------------\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    # Pass the input tensor to the model\n",
    "    with torch.no_grad(): \n",
    "        predictions = model(X_test)\n",
    "    \n",
    "    y_pred = torch.argmax(predictions, dim=1)\n",
    "\n",
    "    y_true = y_test\n",
    "\n",
    "    # Calculate True Positives, False Positives, and False Negatives\n",
    "    tp = ((y_true == 1) & (y_pred == 1)).sum()  # True Positives\n",
    "    fp = ((y_true == 0) & (y_pred == 1)).sum()  # False Positives\n",
    "    fn = ((y_true == 1) & (y_pred == 0)).sum()  # False Negatives\n",
    "    tn = ((y_true == 0) & (y_pred == 0)).sum()  # True Negatives\n",
    "    \n",
    "    # Precision and Recall\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    \n",
    "    # Accuracy\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    \n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    \n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c81649e-c034-4878-90c9-6f467566a838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6666666865348816\n",
      "Recall: 0.5714285969734192\n",
      "Accuracy: 0.8888888955116272\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c765ed-bff1-4b5e-9a3e-5d3bef2d5b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f358f8e8-41c5-4ad6-a1f9-03e6084cee8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Correctly predicted as MVP\n",
      "2003-04 KEVIN GARNETT\n",
      "2011-12 LEBRON JAMES\n",
      "1999-00 SHAQUILLE O'NEAL\n",
      "2001-02 TIM DUNCAN\n",
      "\n",
      "Incorrectly predicted as MVP\n",
      "2022-23 NIKOLA JOKIĆ\n",
      "2001-02 JASON KIDD\n",
      "\n",
      "Incorrectly predicted as non-MVP\n",
      "1984-85 LARRY BIRD\n",
      "1994-95 DAVID ROBINSON\n",
      "2022-23 JOEL EMBIID\n",
      "\n",
      "Correctly predicted as non-MVP\n",
      "1984-85 MAGIC JOHNSON\n",
      "1984-85 MOSES MALONE\n",
      "1984-85 TERRY CUMMINGS\n",
      "1994-95 CHARLES BARKLEY\n",
      "1994-95 HAKEEM OLAJUWON\n",
      "1994-95 KARL MALONE\n",
      "1994-95 PATRICK EWING\n",
      "1994-95 SCOTTIE PIPPEN\n",
      "1994-95 SHAQUILLE O'NEAL\n",
      "2003-04 BEN WALLACE\n",
      "2003-04 JERMAINE O'NEAL\n",
      "2003-04 KOBE BRYANT\n",
      "2003-04 SHAQUILLE O'NEAL\n",
      "2003-04 TIM DUNCAN\n",
      "2011-12 CHRIS PAUL\n",
      "2011-12 DWIGHT HOWARD\n",
      "2011-12 KEVIN DURANT\n",
      "2011-12 KEVIN LOVE\n",
      "2011-12 KOBE BRYANT\n",
      "2011-12 TONY PARKER\n",
      "1999-00 ALLEN IVERSON\n",
      "1999-00 ALONZO MOURNING\n",
      "1999-00 GARY PAYTON\n",
      "1999-00 KARL MALONE\n",
      "1999-00 KEVIN GARNETT\n",
      "1999-00 TIM DUNCAN\n",
      "2022-23 DOMANTAS SABONIS\n",
      "2022-23 DONOVAN MITCHELL\n",
      "2022-23 GIANNIS ANTETOKOUNMPO\n",
      "2022-23 JAYSON TATUM\n",
      "2022-23 SHAI GILGEOUS-ALEXANDER\n",
      "2001-02 CHRIS WEBBER\n",
      "2001-02 GARY PAYTON\n",
      "2001-02 KOBE BRYANT\n",
      "2001-02 SHAQUILLE O'NEAL\n",
      "2001-02 TRACY MCGRADY\n"
     ]
    }
   ],
   "source": [
    "# subset_indexes = _y_test.index\n",
    "\n",
    "y_pred_np = y_pred.numpy()\n",
    "\n",
    "true_positive = _y_test.reset_index().loc[(_y_test.reset_index()['mvp'] == 1) & (y_pred_np == 1)]\n",
    "false_positive = _y_test.reset_index().loc[(_y_test.reset_index()['mvp'] == 0) & (y_pred_np == 1)]\n",
    "false_negative = _y_test.reset_index().loc[(_y_test.reset_index()['mvp'] == 1) & (y_pred_np == 0)]\n",
    "true_negative = _y_test.reset_index().loc[(_y_test.reset_index()['mvp'] == 0) & (y_pred_np == 0)]\n",
    "\n",
    "# print(f\"true_positive:\\n {true_positive}\")\n",
    "# print(f\"false_positive:\\n {false_positive}\")\n",
    "# print(f\"false_negative:\\n {false_negative}\")\n",
    "\n",
    "cross_refs_path = \"/Users/cb/src/nba_mvp_ml/data/processed/by_season/fully_merged/player_index_mapping.csv\"\n",
    "cross_refs = pd.read_csv(cross_refs_path)\n",
    "\n",
    "print('\\nCorrectly predicted as MVP')\n",
    "for i in list(true_positive['index']):\n",
    "    player = cross_refs.iloc[i]['Player']\n",
    "    season = write_season(int(cross_refs.iloc[i]['SEASON_ID']))\n",
    "    \n",
    "    print(f'{season} {player}')\n",
    "\n",
    "print('\\nIncorrectly predicted as MVP')\n",
    "for i in list(false_positive['index']):\n",
    "    player = cross_refs.iloc[i]['Player']\n",
    "    season = write_season(int(cross_refs.iloc[i]['SEASON_ID']))\n",
    "    \n",
    "    print(f'{season} {player}')\n",
    "\n",
    "print('\\nIncorrectly predicted as non-MVP')\n",
    "for i in list(false_negative['index']):\n",
    "    player = cross_refs.iloc[i]['Player']\n",
    "    season = write_season(int(cross_refs.iloc[i]['SEASON_ID']))\n",
    "    \n",
    "    print(f'{season} {player}')\n",
    "\n",
    "print('\\nCorrectly predicted as non-MVP')\n",
    "for i in list(true_negative['index']):\n",
    "    player = cross_refs.iloc[i]['Player']\n",
    "    season = write_season(int(cross_refs.iloc[i]['SEASON_ID']))\n",
    "    \n",
    "    print(f'{season} {player}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9196fe-ecd6-4c2b-b059-76ba6c03a937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4a46d7-3d5c-4c32-b4f2-e1b6b435e430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fb2db1-dfef-42fa-bc55-ba50a680a246",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
