{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "225b4513-9c5c-4a26-92f7-a8fde12373fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import mlflow.pytorch\n",
    "import numpy as np\n",
    "\n",
    "import mlflow\n",
    "\n",
    "import os\n",
    "import sys\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))  # Adjust to your project's structure\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from src.analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ebbbf6b-7a6e-4adc-9542-a6ab2b8d59da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set MLFlow tracking URI (local or server-based)\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")  # Change if using a centralized server\n",
    "\n",
    "# Define the experiment name\n",
    "mlflow.set_experiment(\"MVP Prediction NN\")\n",
    "\n",
    "mlflow.set_tag(\"developer\", \"christophe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "539ebad6-26fa-4517-adcf-5ff79a4d2ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: torch.Size([206, 184]) torch.Size([206])\n",
      "Validation set: torch.Size([44, 184]) torch.Size([44])\n",
      "Test set: torch.Size([45, 184]) torch.Size([45])\n"
     ]
    }
   ],
   "source": [
    "# Load your cleaned dataset\n",
    "data_path = \"/Users/cb/src/nba_mvp_ml/data/processed/by_season/fully_merged/final_stacked_data.csv\"\n",
    "\n",
    "_X, _y = load_and_preprocess_data(data_path, remove_excess_features=False) # X will be normalized\n",
    "\n",
    "\n",
    "# Example input data\n",
    "np.random.seed(42)\n",
    "X =_X.to_numpy().astype(np.float32)\n",
    "y = _y.to_numpy().astype(np.int64)  # Binary labels\n",
    "\n",
    "# Determine sizes for train, validation, and test splits\n",
    "train_size = int(0.7 * len(X))  # 70% for training\n",
    "val_size = int(0.15 * len(X))   # 15% for validation\n",
    "test_size = len(X) - train_size - val_size  # Remaining 15% for testing\n",
    "\n",
    "# Split the datase\n",
    "X_train = torch.tensor(X[:train_size])\n",
    "y_train = torch.tensor(y[:train_size])\n",
    "\n",
    "X_val= torch.tensor(X[train_size:train_size + val_size])\n",
    "y_val= torch.tensor(y[train_size:train_size + val_size])\n",
    "\n",
    "X_test = torch.tensor(X[train_size + val_size:])\n",
    "y_test = torch.tensor(y[train_size + val_size:])\n",
    "\n",
    "_y_test = _y[train_size + val_size:]\n",
    "\n",
    "# Check the shapes of each split\n",
    "print(\"Train set:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set:\", X_val.shape, y_val.shape)\n",
    "print(\"Test set:\", X_test.shape, y_test.shape)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 32\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a7524d4-b75b-4fd1-bfc6-d843699be433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define a simple neural network\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return self.softmax(x)\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = len(_X.columns)\n",
    "hidden_size = 128\n",
    "output_size = 2\n",
    "learning_rate = 0.001\n",
    "num_epochs = 200\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = SimpleMLP(input_size, hidden_size, output_size).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16d94e08-db76-4720-be73-ea73f9cc08c7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Loss: 0.5912\n",
      "Validation Loss: 0.5094, Accuracy: 86.36%\n",
      "Epoch [2/200], Loss: 0.4928\n",
      "Validation Loss: 0.4566, Accuracy: 84.09%\n",
      "Epoch [3/200], Loss: 0.4554\n",
      "Validation Loss: 0.4392, Accuracy: 84.09%\n",
      "Epoch [4/200], Loss: 0.4276\n",
      "Validation Loss: 0.4301, Accuracy: 84.09%\n",
      "Epoch [5/200], Loss: 0.4219\n",
      "Validation Loss: 0.4244, Accuracy: 86.36%\n",
      "Epoch [6/200], Loss: 0.4111\n",
      "Validation Loss: 0.4139, Accuracy: 86.36%\n",
      "Epoch [7/200], Loss: 0.4019\n",
      "Validation Loss: 0.4070, Accuracy: 86.36%\n",
      "Epoch [8/200], Loss: 0.3975\n",
      "Validation Loss: 0.4001, Accuracy: 90.91%\n",
      "Epoch [9/200], Loss: 0.3908\n",
      "Validation Loss: 0.3949, Accuracy: 90.91%\n",
      "Epoch [10/200], Loss: 0.3868\n",
      "Validation Loss: 0.3908, Accuracy: 93.18%\n",
      "Epoch [11/200], Loss: 0.3866\n",
      "Validation Loss: 0.3857, Accuracy: 95.45%\n",
      "Epoch [12/200], Loss: 0.3745\n",
      "Validation Loss: 0.3816, Accuracy: 95.45%\n",
      "Epoch [13/200], Loss: 0.3718\n",
      "Validation Loss: 0.3799, Accuracy: 95.45%\n",
      "Epoch [14/200], Loss: 0.3637\n",
      "Validation Loss: 0.3766, Accuracy: 95.45%\n",
      "Epoch [15/200], Loss: 0.3612\n",
      "Validation Loss: 0.3748, Accuracy: 95.45%\n",
      "Epoch [16/200], Loss: 0.3631\n",
      "Validation Loss: 0.3696, Accuracy: 95.45%\n",
      "Epoch [17/200], Loss: 0.3609\n",
      "Validation Loss: 0.3657, Accuracy: 95.45%\n",
      "Epoch [18/200], Loss: 0.3525\n",
      "Validation Loss: 0.3623, Accuracy: 95.45%\n",
      "Epoch [19/200], Loss: 0.3540\n",
      "Validation Loss: 0.3611, Accuracy: 95.45%\n",
      "Epoch [20/200], Loss: 0.3445\n",
      "Validation Loss: 0.3590, Accuracy: 95.45%\n",
      "Epoch [21/200], Loss: 0.3420\n",
      "Validation Loss: 0.3577, Accuracy: 95.45%\n",
      "Epoch [22/200], Loss: 0.3373\n",
      "Validation Loss: 0.3570, Accuracy: 95.45%\n",
      "Epoch [23/200], Loss: 0.3353\n",
      "Validation Loss: 0.3565, Accuracy: 97.73%\n",
      "Epoch [24/200], Loss: 0.3331\n",
      "Validation Loss: 0.3541, Accuracy: 97.73%\n",
      "Epoch [25/200], Loss: 0.3293\n",
      "Validation Loss: 0.3541, Accuracy: 97.73%\n",
      "Epoch [26/200], Loss: 0.3269\n",
      "Validation Loss: 0.3536, Accuracy: 95.45%\n",
      "Epoch [27/200], Loss: 0.3256\n",
      "Validation Loss: 0.3535, Accuracy: 95.45%\n",
      "Epoch [28/200], Loss: 0.3243\n",
      "Validation Loss: 0.3532, Accuracy: 97.73%\n",
      "Epoch [29/200], Loss: 0.3238\n",
      "Validation Loss: 0.3527, Accuracy: 95.45%\n",
      "Epoch [30/200], Loss: 0.3220\n",
      "Validation Loss: 0.3506, Accuracy: 95.45%\n",
      "Epoch [31/200], Loss: 0.3215\n",
      "Validation Loss: 0.3493, Accuracy: 95.45%\n",
      "Epoch [32/200], Loss: 0.3207\n",
      "Validation Loss: 0.3504, Accuracy: 95.45%\n",
      "Epoch [33/200], Loss: 0.3199\n",
      "Validation Loss: 0.3502, Accuracy: 95.45%\n",
      "Epoch [34/200], Loss: 0.3192\n",
      "Validation Loss: 0.3492, Accuracy: 95.45%\n",
      "Epoch [35/200], Loss: 0.3188\n",
      "Validation Loss: 0.3487, Accuracy: 95.45%\n",
      "Epoch [36/200], Loss: 0.3186\n",
      "Validation Loss: 0.3485, Accuracy: 95.45%\n",
      "Epoch [37/200], Loss: 0.3180\n",
      "Validation Loss: 0.3485, Accuracy: 95.45%\n",
      "Epoch [38/200], Loss: 0.3176\n",
      "Validation Loss: 0.3482, Accuracy: 97.73%\n",
      "Epoch [39/200], Loss: 0.3176\n",
      "Validation Loss: 0.3471, Accuracy: 97.73%\n",
      "Epoch [40/200], Loss: 0.3173\n",
      "Validation Loss: 0.3466, Accuracy: 95.45%\n",
      "Epoch [41/200], Loss: 0.3171\n",
      "Validation Loss: 0.3458, Accuracy: 97.73%\n",
      "Epoch [42/200], Loss: 0.3168\n",
      "Validation Loss: 0.3463, Accuracy: 95.45%\n",
      "Epoch [43/200], Loss: 0.3166\n",
      "Validation Loss: 0.3456, Accuracy: 95.45%\n",
      "Epoch [44/200], Loss: 0.3164\n",
      "Validation Loss: 0.3458, Accuracy: 95.45%\n",
      "Epoch [45/200], Loss: 0.3163\n",
      "Validation Loss: 0.3458, Accuracy: 95.45%\n",
      "Epoch [46/200], Loss: 0.3160\n",
      "Validation Loss: 0.3465, Accuracy: 95.45%\n",
      "Epoch [47/200], Loss: 0.3160\n",
      "Validation Loss: 0.3455, Accuracy: 95.45%\n",
      "Epoch [48/200], Loss: 0.3157\n",
      "Validation Loss: 0.3453, Accuracy: 97.73%\n",
      "Epoch [49/200], Loss: 0.3156\n",
      "Validation Loss: 0.3450, Accuracy: 97.73%\n",
      "Epoch [50/200], Loss: 0.3154\n",
      "Validation Loss: 0.3458, Accuracy: 95.45%\n",
      "Epoch [51/200], Loss: 0.3153\n",
      "Validation Loss: 0.3460, Accuracy: 95.45%\n",
      "Epoch [52/200], Loss: 0.3153\n",
      "Validation Loss: 0.3459, Accuracy: 95.45%\n",
      "Epoch [53/200], Loss: 0.3154\n",
      "Validation Loss: 0.3449, Accuracy: 95.45%\n",
      "Epoch [54/200], Loss: 0.3152\n",
      "Validation Loss: 0.3449, Accuracy: 95.45%\n",
      "Epoch [55/200], Loss: 0.3152\n",
      "Validation Loss: 0.3442, Accuracy: 95.45%\n",
      "Epoch [56/200], Loss: 0.3149\n",
      "Validation Loss: 0.3439, Accuracy: 95.45%\n",
      "Epoch [57/200], Loss: 0.3149\n",
      "Validation Loss: 0.3436, Accuracy: 97.73%\n",
      "Epoch [58/200], Loss: 0.3148\n",
      "Validation Loss: 0.3434, Accuracy: 97.73%\n",
      "Epoch [59/200], Loss: 0.3148\n",
      "Validation Loss: 0.3436, Accuracy: 95.45%\n",
      "Epoch [60/200], Loss: 0.3147\n",
      "Validation Loss: 0.3435, Accuracy: 95.45%\n",
      "Epoch [61/200], Loss: 0.3147\n",
      "Validation Loss: 0.3433, Accuracy: 95.45%\n",
      "Epoch [62/200], Loss: 0.3146\n",
      "Validation Loss: 0.3439, Accuracy: 95.45%\n",
      "Epoch [63/200], Loss: 0.3145\n",
      "Validation Loss: 0.3433, Accuracy: 95.45%\n",
      "Epoch [64/200], Loss: 0.3146\n",
      "Validation Loss: 0.3428, Accuracy: 97.73%\n",
      "Epoch [65/200], Loss: 0.3146\n",
      "Validation Loss: 0.3425, Accuracy: 95.45%\n",
      "Epoch [66/200], Loss: 0.3144\n",
      "Validation Loss: 0.3425, Accuracy: 97.73%\n",
      "Epoch [67/200], Loss: 0.3144\n",
      "Validation Loss: 0.3427, Accuracy: 95.45%\n",
      "Epoch [68/200], Loss: 0.3144\n",
      "Validation Loss: 0.3425, Accuracy: 95.45%\n",
      "Epoch [69/200], Loss: 0.3144\n",
      "Validation Loss: 0.3426, Accuracy: 95.45%\n",
      "Epoch [70/200], Loss: 0.3143\n",
      "Validation Loss: 0.3422, Accuracy: 97.73%\n",
      "Epoch [71/200], Loss: 0.3142\n",
      "Validation Loss: 0.3420, Accuracy: 97.73%\n",
      "Epoch [72/200], Loss: 0.3142\n",
      "Validation Loss: 0.3422, Accuracy: 97.73%\n",
      "Epoch [73/200], Loss: 0.3142\n",
      "Validation Loss: 0.3424, Accuracy: 95.45%\n",
      "Epoch [74/200], Loss: 0.3142\n",
      "Validation Loss: 0.3424, Accuracy: 95.45%\n",
      "Epoch [75/200], Loss: 0.3141\n",
      "Validation Loss: 0.3421, Accuracy: 97.73%\n",
      "Epoch [76/200], Loss: 0.3142\n",
      "Validation Loss: 0.3421, Accuracy: 97.73%\n",
      "Epoch [77/200], Loss: 0.3141\n",
      "Validation Loss: 0.3422, Accuracy: 97.73%\n",
      "Epoch [78/200], Loss: 0.3141\n",
      "Validation Loss: 0.3421, Accuracy: 97.73%\n",
      "Epoch [79/200], Loss: 0.3141\n",
      "Validation Loss: 0.3421, Accuracy: 97.73%\n",
      "Epoch [80/200], Loss: 0.3140\n",
      "Validation Loss: 0.3418, Accuracy: 97.73%\n",
      "Epoch [81/200], Loss: 0.3141\n",
      "Validation Loss: 0.3420, Accuracy: 97.73%\n",
      "Epoch [82/200], Loss: 0.3140\n",
      "Validation Loss: 0.3420, Accuracy: 95.45%\n",
      "Epoch [83/200], Loss: 0.3140\n",
      "Validation Loss: 0.3420, Accuracy: 95.45%\n",
      "Epoch [84/200], Loss: 0.3140\n",
      "Validation Loss: 0.3418, Accuracy: 95.45%\n",
      "Epoch [85/200], Loss: 0.3139\n",
      "Validation Loss: 0.3416, Accuracy: 95.45%\n",
      "Epoch [86/200], Loss: 0.3140\n",
      "Validation Loss: 0.3415, Accuracy: 95.45%\n",
      "Epoch [87/200], Loss: 0.3140\n",
      "Validation Loss: 0.3416, Accuracy: 95.45%\n",
      "Epoch [88/200], Loss: 0.3139\n",
      "Validation Loss: 0.3413, Accuracy: 97.73%\n",
      "Epoch [89/200], Loss: 0.3139\n",
      "Validation Loss: 0.3412, Accuracy: 97.73%\n",
      "Epoch [90/200], Loss: 0.3138\n",
      "Validation Loss: 0.3413, Accuracy: 97.73%\n",
      "Epoch [91/200], Loss: 0.3138\n",
      "Validation Loss: 0.3413, Accuracy: 97.73%\n",
      "Epoch [92/200], Loss: 0.3138\n",
      "Validation Loss: 0.3412, Accuracy: 95.45%\n",
      "Epoch [93/200], Loss: 0.3138\n",
      "Validation Loss: 0.3412, Accuracy: 97.73%\n",
      "Epoch [94/200], Loss: 0.3138\n",
      "Validation Loss: 0.3411, Accuracy: 97.73%\n",
      "Epoch [95/200], Loss: 0.3138\n",
      "Validation Loss: 0.3411, Accuracy: 97.73%\n",
      "Epoch [96/200], Loss: 0.3138\n",
      "Validation Loss: 0.3410, Accuracy: 97.73%\n",
      "Epoch [97/200], Loss: 0.3138\n",
      "Validation Loss: 0.3411, Accuracy: 95.45%\n",
      "Epoch [98/200], Loss: 0.3137\n",
      "Validation Loss: 0.3408, Accuracy: 97.73%\n",
      "Epoch [99/200], Loss: 0.3137\n",
      "Validation Loss: 0.3406, Accuracy: 97.73%\n",
      "Epoch [100/200], Loss: 0.3138\n",
      "Validation Loss: 0.3405, Accuracy: 97.73%\n",
      "Epoch [101/200], Loss: 0.3137\n",
      "Validation Loss: 0.3406, Accuracy: 97.73%\n",
      "Epoch [102/200], Loss: 0.3137\n",
      "Validation Loss: 0.3407, Accuracy: 97.73%\n",
      "Epoch [103/200], Loss: 0.3137\n",
      "Validation Loss: 0.3408, Accuracy: 97.73%\n",
      "Epoch [104/200], Loss: 0.3137\n",
      "Validation Loss: 0.3409, Accuracy: 95.45%\n",
      "Epoch [105/200], Loss: 0.3137\n",
      "Validation Loss: 0.3406, Accuracy: 97.73%\n",
      "Epoch [106/200], Loss: 0.3137\n",
      "Validation Loss: 0.3408, Accuracy: 97.73%\n",
      "Epoch [107/200], Loss: 0.3137\n",
      "Validation Loss: 0.3409, Accuracy: 95.45%\n",
      "Epoch [108/200], Loss: 0.3137\n",
      "Validation Loss: 0.3408, Accuracy: 97.73%\n",
      "Epoch [109/200], Loss: 0.3136\n",
      "Validation Loss: 0.3405, Accuracy: 97.73%\n",
      "Epoch [110/200], Loss: 0.3136\n",
      "Validation Loss: 0.3402, Accuracy: 97.73%\n",
      "Epoch [111/200], Loss: 0.3136\n",
      "Validation Loss: 0.3401, Accuracy: 97.73%\n",
      "Epoch [112/200], Loss: 0.3136\n",
      "Validation Loss: 0.3401, Accuracy: 97.73%\n",
      "Epoch [113/200], Loss: 0.3136\n",
      "Validation Loss: 0.3402, Accuracy: 97.73%\n",
      "Epoch [114/200], Loss: 0.3136\n",
      "Validation Loss: 0.3404, Accuracy: 97.73%\n",
      "Epoch [115/200], Loss: 0.3136\n",
      "Validation Loss: 0.3402, Accuracy: 97.73%\n",
      "Epoch [116/200], Loss: 0.3136\n",
      "Validation Loss: 0.3402, Accuracy: 97.73%\n",
      "Epoch [117/200], Loss: 0.3136\n",
      "Validation Loss: 0.3403, Accuracy: 95.45%\n",
      "Epoch [118/200], Loss: 0.3136\n",
      "Validation Loss: 0.3402, Accuracy: 95.45%\n",
      "Epoch [119/200], Loss: 0.3136\n",
      "Validation Loss: 0.3401, Accuracy: 97.73%\n",
      "Epoch [120/200], Loss: 0.3136\n",
      "Validation Loss: 0.3401, Accuracy: 97.73%\n",
      "Epoch [121/200], Loss: 0.3136\n",
      "Validation Loss: 0.3402, Accuracy: 95.45%\n",
      "Epoch [122/200], Loss: 0.3136\n",
      "Validation Loss: 0.3402, Accuracy: 95.45%\n",
      "Epoch [123/200], Loss: 0.3136\n",
      "Validation Loss: 0.3402, Accuracy: 95.45%\n",
      "Epoch [124/200], Loss: 0.3136\n",
      "Validation Loss: 0.3401, Accuracy: 95.45%\n",
      "Epoch [125/200], Loss: 0.3136\n",
      "Validation Loss: 0.3402, Accuracy: 95.45%\n",
      "Epoch [126/200], Loss: 0.3135\n",
      "Validation Loss: 0.3402, Accuracy: 95.45%\n",
      "Epoch [127/200], Loss: 0.3136\n",
      "Validation Loss: 0.3401, Accuracy: 95.45%\n",
      "Epoch [128/200], Loss: 0.3136\n",
      "Validation Loss: 0.3401, Accuracy: 95.45%\n",
      "Epoch [129/200], Loss: 0.3135\n",
      "Validation Loss: 0.3399, Accuracy: 95.45%\n",
      "Epoch [130/200], Loss: 0.3136\n",
      "Validation Loss: 0.3399, Accuracy: 95.45%\n",
      "Epoch [131/200], Loss: 0.3135\n",
      "Validation Loss: 0.3397, Accuracy: 95.45%\n",
      "Epoch [132/200], Loss: 0.3135\n",
      "Validation Loss: 0.3396, Accuracy: 95.45%\n",
      "Epoch [133/200], Loss: 0.3135\n",
      "Validation Loss: 0.3397, Accuracy: 95.45%\n",
      "Epoch [134/200], Loss: 0.3135\n",
      "Validation Loss: 0.3398, Accuracy: 95.45%\n",
      "Epoch [135/200], Loss: 0.3135\n",
      "Validation Loss: 0.3400, Accuracy: 95.45%\n",
      "Epoch [136/200], Loss: 0.3135\n",
      "Validation Loss: 0.3400, Accuracy: 95.45%\n",
      "Epoch [137/200], Loss: 0.3135\n",
      "Validation Loss: 0.3398, Accuracy: 95.45%\n",
      "Epoch [138/200], Loss: 0.3135\n",
      "Validation Loss: 0.3400, Accuracy: 95.45%\n",
      "Epoch [139/200], Loss: 0.3135\n",
      "Validation Loss: 0.3398, Accuracy: 95.45%\n",
      "Epoch [140/200], Loss: 0.3135\n",
      "Validation Loss: 0.3398, Accuracy: 95.45%\n",
      "Epoch [141/200], Loss: 0.3135\n",
      "Validation Loss: 0.3398, Accuracy: 95.45%\n",
      "Epoch [142/200], Loss: 0.3135\n",
      "Validation Loss: 0.3396, Accuracy: 95.45%\n",
      "Epoch [143/200], Loss: 0.3135\n",
      "Validation Loss: 0.3395, Accuracy: 95.45%\n",
      "Epoch [144/200], Loss: 0.3135\n",
      "Validation Loss: 0.3396, Accuracy: 95.45%\n",
      "Epoch [145/200], Loss: 0.3135\n",
      "Validation Loss: 0.3396, Accuracy: 95.45%\n",
      "Epoch [146/200], Loss: 0.3135\n",
      "Validation Loss: 0.3397, Accuracy: 95.45%\n",
      "Epoch [147/200], Loss: 0.3135\n",
      "Validation Loss: 0.3396, Accuracy: 95.45%\n",
      "Epoch [148/200], Loss: 0.3135\n",
      "Validation Loss: 0.3397, Accuracy: 95.45%\n",
      "Epoch [149/200], Loss: 0.3135\n",
      "Validation Loss: 0.3396, Accuracy: 95.45%\n",
      "Epoch [150/200], Loss: 0.3135\n",
      "Validation Loss: 0.3396, Accuracy: 95.45%\n",
      "Epoch [151/200], Loss: 0.3135\n",
      "Validation Loss: 0.3396, Accuracy: 95.45%\n",
      "Epoch [152/200], Loss: 0.3135\n",
      "Validation Loss: 0.3395, Accuracy: 95.45%\n",
      "Epoch [153/200], Loss: 0.3134\n",
      "Validation Loss: 0.3395, Accuracy: 95.45%\n",
      "Epoch [154/200], Loss: 0.3134\n",
      "Validation Loss: 0.3395, Accuracy: 95.45%\n",
      "Epoch [155/200], Loss: 0.3135\n",
      "Validation Loss: 0.3395, Accuracy: 95.45%\n",
      "Epoch [156/200], Loss: 0.3135\n",
      "Validation Loss: 0.3395, Accuracy: 95.45%\n",
      "Epoch [157/200], Loss: 0.3134\n",
      "Validation Loss: 0.3395, Accuracy: 95.45%\n",
      "Epoch [158/200], Loss: 0.3134\n",
      "Validation Loss: 0.3395, Accuracy: 95.45%\n",
      "Epoch [159/200], Loss: 0.3134\n",
      "Validation Loss: 0.3394, Accuracy: 95.45%\n",
      "Epoch [160/200], Loss: 0.3134\n",
      "Validation Loss: 0.3392, Accuracy: 95.45%\n",
      "Epoch [161/200], Loss: 0.3134\n",
      "Validation Loss: 0.3392, Accuracy: 95.45%\n",
      "Epoch [162/200], Loss: 0.3134\n",
      "Validation Loss: 0.3392, Accuracy: 95.45%\n",
      "Epoch [163/200], Loss: 0.3134\n",
      "Validation Loss: 0.3391, Accuracy: 95.45%\n",
      "Epoch [164/200], Loss: 0.3134\n",
      "Validation Loss: 0.3392, Accuracy: 95.45%\n",
      "Epoch [165/200], Loss: 0.3134\n",
      "Validation Loss: 0.3394, Accuracy: 95.45%\n",
      "Epoch [166/200], Loss: 0.3134\n",
      "Validation Loss: 0.3394, Accuracy: 95.45%\n",
      "Epoch [167/200], Loss: 0.3134\n",
      "Validation Loss: 0.3393, Accuracy: 95.45%\n",
      "Epoch [168/200], Loss: 0.3134\n",
      "Validation Loss: 0.3393, Accuracy: 95.45%\n",
      "Epoch [169/200], Loss: 0.3134\n",
      "Validation Loss: 0.3393, Accuracy: 95.45%\n",
      "Epoch [170/200], Loss: 0.3134\n",
      "Validation Loss: 0.3393, Accuracy: 95.45%\n",
      "Epoch [171/200], Loss: 0.3134\n",
      "Validation Loss: 0.3392, Accuracy: 95.45%\n",
      "Epoch [172/200], Loss: 0.3134\n",
      "Validation Loss: 0.3393, Accuracy: 95.45%\n",
      "Epoch [173/200], Loss: 0.3134\n",
      "Validation Loss: 0.3391, Accuracy: 95.45%\n",
      "Epoch [174/200], Loss: 0.3134\n",
      "Validation Loss: 0.3391, Accuracy: 95.45%\n",
      "Epoch [175/200], Loss: 0.3134\n",
      "Validation Loss: 0.3392, Accuracy: 95.45%\n",
      "Epoch [176/200], Loss: 0.3134\n",
      "Validation Loss: 0.3392, Accuracy: 95.45%\n",
      "Epoch [177/200], Loss: 0.3134\n",
      "Validation Loss: 0.3391, Accuracy: 95.45%\n",
      "Epoch [178/200], Loss: 0.3134\n",
      "Validation Loss: 0.3392, Accuracy: 95.45%\n",
      "Epoch [179/200], Loss: 0.3134\n",
      "Validation Loss: 0.3392, Accuracy: 95.45%\n",
      "Epoch [180/200], Loss: 0.3134\n",
      "Validation Loss: 0.3391, Accuracy: 95.45%\n",
      "Epoch [181/200], Loss: 0.3134\n",
      "Validation Loss: 0.3390, Accuracy: 95.45%\n",
      "Epoch [182/200], Loss: 0.3134\n",
      "Validation Loss: 0.3390, Accuracy: 95.45%\n",
      "Epoch [183/200], Loss: 0.3134\n",
      "Validation Loss: 0.3390, Accuracy: 95.45%\n",
      "Epoch [184/200], Loss: 0.3134\n",
      "Validation Loss: 0.3391, Accuracy: 95.45%\n",
      "Epoch [185/200], Loss: 0.3134\n",
      "Validation Loss: 0.3391, Accuracy: 95.45%\n",
      "Epoch [186/200], Loss: 0.3134\n",
      "Validation Loss: 0.3392, Accuracy: 95.45%\n",
      "Epoch [187/200], Loss: 0.3134\n",
      "Validation Loss: 0.3391, Accuracy: 95.45%\n",
      "Epoch [188/200], Loss: 0.3134\n",
      "Validation Loss: 0.3390, Accuracy: 95.45%\n",
      "Epoch [189/200], Loss: 0.3134\n",
      "Validation Loss: 0.3389, Accuracy: 95.45%\n",
      "Epoch [190/200], Loss: 0.3134\n",
      "Validation Loss: 0.3389, Accuracy: 95.45%\n",
      "Epoch [191/200], Loss: 0.3134\n",
      "Validation Loss: 0.3389, Accuracy: 95.45%\n",
      "Epoch [192/200], Loss: 0.3134\n",
      "Validation Loss: 0.3389, Accuracy: 95.45%\n",
      "Epoch [193/200], Loss: 0.3134\n",
      "Validation Loss: 0.3389, Accuracy: 95.45%\n",
      "Epoch [194/200], Loss: 0.3134\n",
      "Validation Loss: 0.3388, Accuracy: 95.45%\n",
      "Epoch [195/200], Loss: 0.3134\n",
      "Validation Loss: 0.3388, Accuracy: 95.45%\n",
      "Epoch [196/200], Loss: 0.3134\n",
      "Validation Loss: 0.3390, Accuracy: 95.45%\n",
      "Epoch [197/200], Loss: 0.3134\n",
      "Validation Loss: 0.3390, Accuracy: 95.45%\n",
      "Epoch [198/200], Loss: 0.3134\n",
      "Validation Loss: 0.3389, Accuracy: 95.45%\n",
      "Epoch [199/200], Loss: 0.3134\n",
      "Validation Loss: 0.3389, Accuracy: 95.45%\n",
      "Epoch [200/200], Loss: 0.3134\n",
      "Validation Loss: 0.3389, Accuracy: 95.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/05 20:25:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete and logged in MLflow.\n",
      "Precision: 0.800000011920929\n",
      "Recall: 0.5714285969734192\n",
      "Accuracy: 0.9111111164093018\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(nested=True):\n",
    "    # Log hyperparameters\n",
    "    mlflow.log_param(\"input_size\", input_size)\n",
    "    mlflow.log_param(\"hidden_size\", hidden_size)\n",
    "    mlflow.log_param(\"output_size\", output_size)\n",
    "    mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "    mlflow.log_param(\"batch_size\", batch_size)\n",
    "    mlflow.log_param(\"num_epochs\", num_epochs)\n",
    "    mlflow.log_param(\"n_features\", len(_X.columns))\n",
    "\n",
    "    mlflow.log_param(\"model_name\", 'neural network')\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_train_loss:.4f}\")\n",
    "        mlflow.log_metric(\"train_loss\", avg_train_loss, step=epoch)\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == targets).sum().item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = 100 * correct / total\n",
    "        print(f\"Validation Loss: {avg_val_loss:.4f}, Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "        mlflow.log_metric(\"val_loss\", avg_val_loss, step=epoch)\n",
    "        mlflow.log_metric(\"val_accuracy\", val_accuracy, step=epoch)\n",
    "\n",
    "    # Log the trained model\n",
    "    mlflow.pytorch.log_model(model, \"model\")\n",
    "\n",
    "    print(\"Model training complete and logged in MLflow.\")\n",
    "\n",
    "\n",
    "    # TEST PERFORMANCE ALANYSIS ------------------------------------------------------------------------------\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    # Pass the input tensor to the model\n",
    "    with torch.no_grad(): \n",
    "        predictions = model(X_test)\n",
    "    \n",
    "    y_pred = torch.argmax(predictions, dim=1)\n",
    "\n",
    "    y_true = y_test\n",
    "\n",
    "    # Calculate True Positives, False Positives, and False Negatives\n",
    "    tp = ((y_true == 1) & (y_pred == 1)).sum()  # True Positives\n",
    "    fp = ((y_true == 0) & (y_pred == 1)).sum()  # False Positives\n",
    "    fn = ((y_true == 1) & (y_pred == 0)).sum()  # False Negatives\n",
    "    tn = ((y_true == 0) & (y_pred == 0)).sum()  # True Negatives\n",
    "    \n",
    "    # Precision and Recall\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    \n",
    "    # Accuracy\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    \n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    \n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c81649e-c034-4878-90c9-6f467566a838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.800000011920929\n",
      "Recall: 0.5714285969734192\n",
      "Accuracy: 0.9111111164093018\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f358f8e8-41c5-4ad6-a1f9-03e6084cee8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Correctly predicted as MVP\n",
      "2003-04 KEVIN GARNETT\n",
      "2011-12 LEBRON JAMES\n",
      "1999-00 SHAQUILLE O'NEAL\n",
      "2001-02 TIM DUNCAN\n",
      "\n",
      "Incorrectly predicted as MVP\n",
      "2001-02 JASON KIDD\n",
      "\n",
      "Incorrectly predicted as non-MVP\n",
      "1984-85 LARRY BIRD\n",
      "1994-95 DAVID ROBINSON\n",
      "2022-23 JOEL EMBIID\n",
      "\n",
      "Correctly predicted as non-MVP\n",
      "1984-85 MAGIC JOHNSON\n",
      "1984-85 MOSES MALONE\n",
      "1984-85 TERRY CUMMINGS\n",
      "1994-95 CHARLES BARKLEY\n",
      "1994-95 HAKEEM OLAJUWON\n",
      "1994-95 KARL MALONE\n",
      "1994-95 PATRICK EWING\n",
      "1994-95 SCOTTIE PIPPEN\n",
      "1994-95 SHAQUILLE O'NEAL\n",
      "2003-04 BEN WALLACE\n",
      "2003-04 JERMAINE O'NEAL\n",
      "2003-04 KOBE BRYANT\n",
      "2003-04 SHAQUILLE O'NEAL\n",
      "2003-04 TIM DUNCAN\n",
      "2011-12 CHRIS PAUL\n",
      "2011-12 DWIGHT HOWARD\n",
      "2011-12 KEVIN DURANT\n",
      "2011-12 KEVIN LOVE\n",
      "2011-12 KOBE BRYANT\n",
      "2011-12 TONY PARKER\n",
      "1999-00 ALLEN IVERSON\n",
      "1999-00 ALONZO MOURNING\n",
      "1999-00 GARY PAYTON\n",
      "1999-00 KARL MALONE\n",
      "1999-00 KEVIN GARNETT\n",
      "1999-00 TIM DUNCAN\n",
      "2022-23 DOMANTAS SABONIS\n",
      "2022-23 DONOVAN MITCHELL\n",
      "2022-23 GIANNIS ANTETOKOUNMPO\n",
      "2022-23 JAYSON TATUM\n",
      "2022-23 NIKOLA JOKIÄ†\n",
      "2022-23 SHAI GILGEOUS-ALEXANDER\n",
      "2001-02 CHRIS WEBBER\n",
      "2001-02 GARY PAYTON\n",
      "2001-02 KOBE BRYANT\n",
      "2001-02 SHAQUILLE O'NEAL\n",
      "2001-02 TRACY MCGRADY\n"
     ]
    }
   ],
   "source": [
    "# subset_indexes = _y_test.index\n",
    "\n",
    "y_pred_np = y_pred.numpy()\n",
    "\n",
    "true_positive = _y_test.reset_index().loc[(_y_test.reset_index()['mvp'] == 1) & (y_pred_np == 1)]\n",
    "false_positive = _y_test.reset_index().loc[(_y_test.reset_index()['mvp'] == 0) & (y_pred_np == 1)]\n",
    "false_negative = _y_test.reset_index().loc[(_y_test.reset_index()['mvp'] == 1) & (y_pred_np == 0)]\n",
    "true_negative = _y_test.reset_index().loc[(_y_test.reset_index()['mvp'] == 0) & (y_pred_np == 0)]\n",
    "\n",
    "# print(f\"true_positive:\\n {true_positive}\")\n",
    "# print(f\"false_positive:\\n {false_positive}\")\n",
    "# print(f\"false_negative:\\n {false_negative}\")\n",
    "\n",
    "cross_refs_path = \"/Users/cb/src/nba_mvp_ml/data/processed/by_season/fully_merged/player_index_mapping.csv\"\n",
    "cross_refs = pd.read_csv(cross_refs_path)\n",
    "\n",
    "print('\\nCorrectly predicted as MVP')\n",
    "for i in list(true_positive['index']):\n",
    "    player = cross_refs.iloc[i]['Player']\n",
    "    season = write_season(int(cross_refs.iloc[i]['SEASON_ID']))\n",
    "    \n",
    "    print(f'{season} {player}')\n",
    "\n",
    "print('\\nIncorrectly predicted as MVP')\n",
    "for i in list(false_positive['index']):\n",
    "    player = cross_refs.iloc[i]['Player']\n",
    "    season = write_season(int(cross_refs.iloc[i]['SEASON_ID']))\n",
    "    \n",
    "    print(f'{season} {player}')\n",
    "\n",
    "print('\\nIncorrectly predicted as non-MVP')\n",
    "for i in list(false_negative['index']):\n",
    "    player = cross_refs.iloc[i]['Player']\n",
    "    season = write_season(int(cross_refs.iloc[i]['SEASON_ID']))\n",
    "    \n",
    "    print(f'{season} {player}')\n",
    "\n",
    "print('\\nCorrectly predicted as non-MVP')\n",
    "for i in list(true_negative['index']):\n",
    "    player = cross_refs.iloc[i]['Player']\n",
    "    season = write_season(int(cross_refs.iloc[i]['SEASON_ID']))\n",
    "    \n",
    "    print(f'{season} {player}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9196fe-ecd6-4c2b-b059-76ba6c03a937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd4a46d7-3d5c-4c32-b4f2-e1b6b435e430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'FGM', 'FGA_player', 'FG3M', 'FG3A', 'FTM', 'FTA_player',\n",
       "       'OREB', 'DREB', 'REB',\n",
       "       ...\n",
       "       'sentiment_8', 'sentiment_9', 'sentiment_10', 'sentiment_11',\n",
       "       'sentiment_12', 'sentiment_13', 'sentiment_14', 'sentiment_15',\n",
       "       'sentiment_avg', 'WS'],\n",
       "      dtype='object', length=184)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fb2db1-dfef-42fa-bc55-ba50a680a246",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
