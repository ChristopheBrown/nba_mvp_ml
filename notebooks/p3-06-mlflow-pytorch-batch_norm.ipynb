{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "225b4513-9c5c-4a26-92f7-a8fde12373fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import mlflow.pytorch\n",
    "import numpy as np\n",
    "\n",
    "import mlflow\n",
    "\n",
    "import os\n",
    "import sys\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))  # Adjust to your project's structure\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from src.analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ebbbf6b-7a6e-4adc-9542-a6ab2b8d59da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set MLFlow tracking URI (local or server-based)\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")  # Change if using a centralized server\n",
    "\n",
    "# Define the experiment name\n",
    "mlflow.set_experiment(\"MVP Prediction NN\")\n",
    "\n",
    "mlflow.set_tag(\"developer\", \"christophe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "539ebad6-26fa-4517-adcf-5ff79a4d2ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: torch.Size([206, 184]) torch.Size([206])\n",
      "Validation set: torch.Size([44, 184]) torch.Size([44])\n",
      "Test set: torch.Size([45, 184]) torch.Size([45])\n"
     ]
    }
   ],
   "source": [
    "# Load your cleaned dataset\n",
    "data_path = \"/Users/cb/src/nba_mvp_ml/data/processed/by_season/fully_merged/final_stacked_data.csv\"\n",
    "\n",
    "_X, _y = load_and_preprocess_data(data_path, remove_excess_features=False) # X will be normalized\n",
    "\n",
    "\n",
    "# Example input data\n",
    "np.random.seed(42)\n",
    "X =_X.to_numpy().astype(np.float32)\n",
    "y = _y.to_numpy().astype(np.int64)  # Binary labels\n",
    "\n",
    "# Determine sizes for train, validation, and test splits\n",
    "train_size = int(0.7 * len(X))  # 70% for training\n",
    "val_size = int(0.15 * len(X))   # 15% for validation\n",
    "test_size = len(X) - train_size - val_size  # Remaining 15% for testing\n",
    "\n",
    "# Split the datase\n",
    "X_train = torch.tensor(X[:train_size])\n",
    "y_train = torch.tensor(y[:train_size])\n",
    "\n",
    "X_val= torch.tensor(X[train_size:train_size + val_size])\n",
    "y_val= torch.tensor(y[train_size:train_size + val_size])\n",
    "\n",
    "X_test = torch.tensor(X[train_size + val_size:])\n",
    "y_test = torch.tensor(y[train_size + val_size:])\n",
    "\n",
    "_y_test = _y[train_size + val_size:]\n",
    "\n",
    "# Check the shapes of each split\n",
    "print(\"Train set:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set:\", X_val.shape, y_val.shape)\n",
    "print(\"Test set:\", X_test.shape, y_test.shape)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 32\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a7524d4-b75b-4fd1-bfc6-d843699be433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define a simple neural network\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn1(x)  # Batch normalization\n",
    "        x = self.fc2(x)\n",
    "        return self.softmax(x)\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = len(_X.columns)\n",
    "hidden_size = 64\n",
    "output_size = 2\n",
    "learning_rate = 0.001\n",
    "num_epochs = 200\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = SimpleMLP(input_size, hidden_size, output_size).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16d94e08-db76-4720-be73-ea73f9cc08c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Loss: 0.6695\n",
      "Validation Loss: 0.6842, Accuracy: 52.27%\n",
      "Epoch [2/200], Loss: 0.6041\n",
      "Validation Loss: 0.6235, Accuracy: 70.45%\n",
      "Epoch [3/200], Loss: 0.5718\n",
      "Validation Loss: 0.5835, Accuracy: 77.27%\n",
      "Epoch [4/200], Loss: 0.5561\n",
      "Validation Loss: 0.5597, Accuracy: 79.55%\n",
      "Epoch [5/200], Loss: 0.5255\n",
      "Validation Loss: 0.5483, Accuracy: 77.27%\n",
      "Epoch [6/200], Loss: 0.5309\n",
      "Validation Loss: 0.5580, Accuracy: 75.00%\n",
      "Epoch [7/200], Loss: 0.4857\n",
      "Validation Loss: 0.5411, Accuracy: 75.00%\n",
      "Epoch [8/200], Loss: 0.4871\n",
      "Validation Loss: 0.5176, Accuracy: 77.27%\n",
      "Epoch [9/200], Loss: 0.4629\n",
      "Validation Loss: 0.5274, Accuracy: 77.27%\n",
      "Epoch [10/200], Loss: 0.4485\n",
      "Validation Loss: 0.5180, Accuracy: 79.55%\n",
      "Epoch [11/200], Loss: 0.4435\n",
      "Validation Loss: 0.5001, Accuracy: 84.09%\n",
      "Epoch [12/200], Loss: 0.4452\n",
      "Validation Loss: 0.5019, Accuracy: 77.27%\n",
      "Epoch [13/200], Loss: 0.4137\n",
      "Validation Loss: 0.5057, Accuracy: 79.55%\n",
      "Epoch [14/200], Loss: 0.4348\n",
      "Validation Loss: 0.4917, Accuracy: 84.09%\n",
      "Epoch [15/200], Loss: 0.3913\n",
      "Validation Loss: 0.4705, Accuracy: 86.36%\n",
      "Epoch [16/200], Loss: 0.3988\n",
      "Validation Loss: 0.4769, Accuracy: 79.55%\n",
      "Epoch [17/200], Loss: 0.3814\n",
      "Validation Loss: 0.4451, Accuracy: 86.36%\n",
      "Epoch [18/200], Loss: 0.3688\n",
      "Validation Loss: 0.4263, Accuracy: 88.64%\n",
      "Epoch [19/200], Loss: 0.3597\n",
      "Validation Loss: 0.4143, Accuracy: 90.91%\n",
      "Epoch [20/200], Loss: 0.3653\n",
      "Validation Loss: 0.4087, Accuracy: 90.91%\n",
      "Epoch [21/200], Loss: 0.3573\n",
      "Validation Loss: 0.3908, Accuracy: 95.45%\n",
      "Epoch [22/200], Loss: 0.3562\n",
      "Validation Loss: 0.3800, Accuracy: 93.18%\n",
      "Epoch [23/200], Loss: 0.3693\n",
      "Validation Loss: 0.4168, Accuracy: 88.64%\n",
      "Epoch [24/200], Loss: 0.3469\n",
      "Validation Loss: 0.3949, Accuracy: 90.91%\n",
      "Epoch [25/200], Loss: 0.3495\n",
      "Validation Loss: 0.3958, Accuracy: 88.64%\n",
      "Epoch [26/200], Loss: 0.3481\n",
      "Validation Loss: 0.4064, Accuracy: 88.64%\n",
      "Epoch [27/200], Loss: 0.3446\n",
      "Validation Loss: 0.4028, Accuracy: 90.91%\n",
      "Epoch [28/200], Loss: 0.3393\n",
      "Validation Loss: 0.3913, Accuracy: 93.18%\n",
      "Epoch [29/200], Loss: 0.3371\n",
      "Validation Loss: 0.3827, Accuracy: 93.18%\n",
      "Epoch [30/200], Loss: 0.3426\n",
      "Validation Loss: 0.3886, Accuracy: 93.18%\n",
      "Epoch [31/200], Loss: 0.3424\n",
      "Validation Loss: 0.3851, Accuracy: 93.18%\n",
      "Epoch [32/200], Loss: 0.3393\n",
      "Validation Loss: 0.3769, Accuracy: 93.18%\n",
      "Epoch [33/200], Loss: 0.3477\n",
      "Validation Loss: 0.3975, Accuracy: 90.91%\n",
      "Epoch [34/200], Loss: 0.3349\n",
      "Validation Loss: 0.3807, Accuracy: 90.91%\n",
      "Epoch [35/200], Loss: 0.3405\n",
      "Validation Loss: 0.3874, Accuracy: 90.91%\n",
      "Epoch [36/200], Loss: 0.3424\n",
      "Validation Loss: 0.3810, Accuracy: 93.18%\n",
      "Epoch [37/200], Loss: 0.3352\n",
      "Validation Loss: 0.3714, Accuracy: 95.45%\n",
      "Epoch [38/200], Loss: 0.3341\n",
      "Validation Loss: 0.3846, Accuracy: 88.64%\n",
      "Epoch [39/200], Loss: 0.3318\n",
      "Validation Loss: 0.3768, Accuracy: 90.91%\n",
      "Epoch [40/200], Loss: 0.3327\n",
      "Validation Loss: 0.3752, Accuracy: 90.91%\n",
      "Epoch [41/200], Loss: 0.3330\n",
      "Validation Loss: 0.3626, Accuracy: 90.91%\n",
      "Epoch [42/200], Loss: 0.3402\n",
      "Validation Loss: 0.3606, Accuracy: 93.18%\n",
      "Epoch [43/200], Loss: 0.3316\n",
      "Validation Loss: 0.3500, Accuracy: 95.45%\n",
      "Epoch [44/200], Loss: 0.3355\n",
      "Validation Loss: 0.3593, Accuracy: 95.45%\n",
      "Epoch [45/200], Loss: 0.3335\n",
      "Validation Loss: 0.3688, Accuracy: 95.45%\n",
      "Epoch [46/200], Loss: 0.3317\n",
      "Validation Loss: 0.3598, Accuracy: 95.45%\n",
      "Epoch [47/200], Loss: 0.3329\n",
      "Validation Loss: 0.3631, Accuracy: 93.18%\n",
      "Epoch [48/200], Loss: 0.3418\n",
      "Validation Loss: 0.3769, Accuracy: 90.91%\n",
      "Epoch [49/200], Loss: 0.3356\n",
      "Validation Loss: 0.3986, Accuracy: 90.91%\n",
      "Epoch [50/200], Loss: 0.3321\n",
      "Validation Loss: 0.3723, Accuracy: 93.18%\n",
      "Epoch [51/200], Loss: 0.3333\n",
      "Validation Loss: 0.3512, Accuracy: 95.45%\n",
      "Epoch [52/200], Loss: 0.3315\n",
      "Validation Loss: 0.3500, Accuracy: 95.45%\n",
      "Epoch [53/200], Loss: 0.3290\n",
      "Validation Loss: 0.3467, Accuracy: 97.73%\n",
      "Epoch [54/200], Loss: 0.3403\n",
      "Validation Loss: 0.3487, Accuracy: 95.45%\n",
      "Epoch [55/200], Loss: 0.3318\n",
      "Validation Loss: 0.3501, Accuracy: 95.45%\n",
      "Epoch [56/200], Loss: 0.3395\n",
      "Validation Loss: 0.3624, Accuracy: 93.18%\n",
      "Epoch [57/200], Loss: 0.3434\n",
      "Validation Loss: 0.3710, Accuracy: 90.91%\n",
      "Epoch [58/200], Loss: 0.3317\n",
      "Validation Loss: 0.3599, Accuracy: 93.18%\n",
      "Epoch [59/200], Loss: 0.3281\n",
      "Validation Loss: 0.3541, Accuracy: 95.45%\n",
      "Epoch [60/200], Loss: 0.3368\n",
      "Validation Loss: 0.3577, Accuracy: 93.18%\n",
      "Epoch [61/200], Loss: 0.3252\n",
      "Validation Loss: 0.3538, Accuracy: 95.45%\n",
      "Epoch [62/200], Loss: 0.3246\n",
      "Validation Loss: 0.3467, Accuracy: 95.45%\n",
      "Epoch [63/200], Loss: 0.3246\n",
      "Validation Loss: 0.3436, Accuracy: 97.73%\n",
      "Epoch [64/200], Loss: 0.3349\n",
      "Validation Loss: 0.3431, Accuracy: 97.73%\n",
      "Epoch [65/200], Loss: 0.3297\n",
      "Validation Loss: 0.3547, Accuracy: 95.45%\n",
      "Epoch [66/200], Loss: 0.3298\n",
      "Validation Loss: 0.3615, Accuracy: 93.18%\n",
      "Epoch [67/200], Loss: 0.3315\n",
      "Validation Loss: 0.3665, Accuracy: 93.18%\n",
      "Epoch [68/200], Loss: 0.3286\n",
      "Validation Loss: 0.3620, Accuracy: 93.18%\n",
      "Epoch [69/200], Loss: 0.3290\n",
      "Validation Loss: 0.3563, Accuracy: 90.91%\n",
      "Epoch [70/200], Loss: 0.3289\n",
      "Validation Loss: 0.3532, Accuracy: 95.45%\n",
      "Epoch [71/200], Loss: 0.3254\n",
      "Validation Loss: 0.3572, Accuracy: 95.45%\n",
      "Epoch [72/200], Loss: 0.3327\n",
      "Validation Loss: 0.3555, Accuracy: 93.18%\n",
      "Epoch [73/200], Loss: 0.3271\n",
      "Validation Loss: 0.3572, Accuracy: 93.18%\n",
      "Epoch [74/200], Loss: 0.3265\n",
      "Validation Loss: 0.3547, Accuracy: 90.91%\n",
      "Epoch [75/200], Loss: 0.3258\n",
      "Validation Loss: 0.3603, Accuracy: 90.91%\n",
      "Epoch [76/200], Loss: 0.3255\n",
      "Validation Loss: 0.3622, Accuracy: 93.18%\n",
      "Epoch [77/200], Loss: 0.3299\n",
      "Validation Loss: 0.3580, Accuracy: 93.18%\n",
      "Epoch [78/200], Loss: 0.3313\n",
      "Validation Loss: 0.3676, Accuracy: 93.18%\n",
      "Epoch [79/200], Loss: 0.3296\n",
      "Validation Loss: 0.3615, Accuracy: 95.45%\n",
      "Epoch [80/200], Loss: 0.3253\n",
      "Validation Loss: 0.3641, Accuracy: 93.18%\n",
      "Epoch [81/200], Loss: 0.3286\n",
      "Validation Loss: 0.3572, Accuracy: 93.18%\n",
      "Epoch [82/200], Loss: 0.3244\n",
      "Validation Loss: 0.3592, Accuracy: 93.18%\n",
      "Epoch [83/200], Loss: 0.3250\n",
      "Validation Loss: 0.3623, Accuracy: 93.18%\n",
      "Epoch [84/200], Loss: 0.3207\n",
      "Validation Loss: 0.3661, Accuracy: 93.18%\n",
      "Epoch [85/200], Loss: 0.3206\n",
      "Validation Loss: 0.3639, Accuracy: 93.18%\n",
      "Epoch [86/200], Loss: 0.3203\n",
      "Validation Loss: 0.3628, Accuracy: 93.18%\n",
      "Epoch [87/200], Loss: 0.3219\n",
      "Validation Loss: 0.3626, Accuracy: 93.18%\n",
      "Epoch [88/200], Loss: 0.3196\n",
      "Validation Loss: 0.3622, Accuracy: 93.18%\n",
      "Epoch [89/200], Loss: 0.3201\n",
      "Validation Loss: 0.3631, Accuracy: 90.91%\n",
      "Epoch [90/200], Loss: 0.3256\n",
      "Validation Loss: 0.3646, Accuracy: 90.91%\n",
      "Epoch [91/200], Loss: 0.3186\n",
      "Validation Loss: 0.3699, Accuracy: 93.18%\n",
      "Epoch [92/200], Loss: 0.3202\n",
      "Validation Loss: 0.3639, Accuracy: 93.18%\n",
      "Epoch [93/200], Loss: 0.3170\n",
      "Validation Loss: 0.3677, Accuracy: 93.18%\n",
      "Epoch [94/200], Loss: 0.3186\n",
      "Validation Loss: 0.3645, Accuracy: 93.18%\n",
      "Epoch [95/200], Loss: 0.3214\n",
      "Validation Loss: 0.3611, Accuracy: 93.18%\n",
      "Epoch [96/200], Loss: 0.3249\n",
      "Validation Loss: 0.3680, Accuracy: 93.18%\n",
      "Epoch [97/200], Loss: 0.3199\n",
      "Validation Loss: 0.3618, Accuracy: 93.18%\n",
      "Epoch [98/200], Loss: 0.3165\n",
      "Validation Loss: 0.3646, Accuracy: 93.18%\n",
      "Epoch [99/200], Loss: 0.3177\n",
      "Validation Loss: 0.3880, Accuracy: 90.91%\n",
      "Epoch [100/200], Loss: 0.3172\n",
      "Validation Loss: 0.3656, Accuracy: 93.18%\n",
      "Epoch [101/200], Loss: 0.3190\n",
      "Validation Loss: 0.3657, Accuracy: 90.91%\n",
      "Epoch [102/200], Loss: 0.3150\n",
      "Validation Loss: 0.3719, Accuracy: 90.91%\n",
      "Epoch [103/200], Loss: 0.3157\n",
      "Validation Loss: 0.3665, Accuracy: 90.91%\n",
      "Epoch [104/200], Loss: 0.3148\n",
      "Validation Loss: 0.3515, Accuracy: 95.45%\n",
      "Epoch [105/200], Loss: 0.3147\n",
      "Validation Loss: 0.3510, Accuracy: 93.18%\n",
      "Epoch [106/200], Loss: 0.3172\n",
      "Validation Loss: 0.3563, Accuracy: 93.18%\n",
      "Epoch [107/200], Loss: 0.3154\n",
      "Validation Loss: 0.3670, Accuracy: 93.18%\n",
      "Epoch [108/200], Loss: 0.3146\n",
      "Validation Loss: 0.3751, Accuracy: 90.91%\n",
      "Epoch [109/200], Loss: 0.3150\n",
      "Validation Loss: 0.3677, Accuracy: 93.18%\n",
      "Epoch [110/200], Loss: 0.3160\n",
      "Validation Loss: 0.3749, Accuracy: 90.91%\n",
      "Epoch [111/200], Loss: 0.3142\n",
      "Validation Loss: 0.3729, Accuracy: 90.91%\n",
      "Epoch [112/200], Loss: 0.3142\n",
      "Validation Loss: 0.3738, Accuracy: 90.91%\n",
      "Epoch [113/200], Loss: 0.3140\n",
      "Validation Loss: 0.3711, Accuracy: 90.91%\n",
      "Epoch [114/200], Loss: 0.3147\n",
      "Validation Loss: 0.3716, Accuracy: 90.91%\n",
      "Epoch [115/200], Loss: 0.3142\n",
      "Validation Loss: 0.3711, Accuracy: 90.91%\n",
      "Epoch [116/200], Loss: 0.3138\n",
      "Validation Loss: 0.3698, Accuracy: 90.91%\n",
      "Epoch [117/200], Loss: 0.3145\n",
      "Validation Loss: 0.3682, Accuracy: 90.91%\n",
      "Epoch [118/200], Loss: 0.3144\n",
      "Validation Loss: 0.3680, Accuracy: 93.18%\n",
      "Epoch [119/200], Loss: 0.3147\n",
      "Validation Loss: 0.3682, Accuracy: 93.18%\n",
      "Epoch [120/200], Loss: 0.3166\n",
      "Validation Loss: 0.3732, Accuracy: 90.91%\n",
      "Epoch [121/200], Loss: 0.3167\n",
      "Validation Loss: 0.3742, Accuracy: 90.91%\n",
      "Epoch [122/200], Loss: 0.3140\n",
      "Validation Loss: 0.3773, Accuracy: 90.91%\n",
      "Epoch [123/200], Loss: 0.3137\n",
      "Validation Loss: 0.3741, Accuracy: 90.91%\n",
      "Epoch [124/200], Loss: 0.3140\n",
      "Validation Loss: 0.3708, Accuracy: 90.91%\n",
      "Epoch [125/200], Loss: 0.3164\n",
      "Validation Loss: 0.3637, Accuracy: 93.18%\n",
      "Epoch [126/200], Loss: 0.3146\n",
      "Validation Loss: 0.3606, Accuracy: 93.18%\n",
      "Epoch [127/200], Loss: 0.3163\n",
      "Validation Loss: 0.3833, Accuracy: 90.91%\n",
      "Epoch [128/200], Loss: 0.3149\n",
      "Validation Loss: 0.4072, Accuracy: 88.64%\n",
      "Epoch [129/200], Loss: 0.3150\n",
      "Validation Loss: 0.3755, Accuracy: 90.91%\n",
      "Epoch [130/200], Loss: 0.3139\n",
      "Validation Loss: 0.3696, Accuracy: 90.91%\n",
      "Epoch [131/200], Loss: 0.3142\n",
      "Validation Loss: 0.3678, Accuracy: 90.91%\n",
      "Epoch [132/200], Loss: 0.3140\n",
      "Validation Loss: 0.3834, Accuracy: 90.91%\n",
      "Epoch [133/200], Loss: 0.3139\n",
      "Validation Loss: 0.3870, Accuracy: 88.64%\n",
      "Epoch [134/200], Loss: 0.3138\n",
      "Validation Loss: 0.3950, Accuracy: 88.64%\n",
      "Epoch [135/200], Loss: 0.3139\n",
      "Validation Loss: 0.3987, Accuracy: 88.64%\n",
      "Epoch [136/200], Loss: 0.3138\n",
      "Validation Loss: 0.3980, Accuracy: 88.64%\n",
      "Epoch [137/200], Loss: 0.3137\n",
      "Validation Loss: 0.3993, Accuracy: 88.64%\n",
      "Epoch [138/200], Loss: 0.3138\n",
      "Validation Loss: 0.3940, Accuracy: 88.64%\n",
      "Epoch [139/200], Loss: 0.3139\n",
      "Validation Loss: 0.3791, Accuracy: 90.91%\n",
      "Epoch [140/200], Loss: 0.3140\n",
      "Validation Loss: 0.3757, Accuracy: 90.91%\n",
      "Epoch [141/200], Loss: 0.3135\n",
      "Validation Loss: 0.3766, Accuracy: 90.91%\n",
      "Epoch [142/200], Loss: 0.3144\n",
      "Validation Loss: 0.3798, Accuracy: 90.91%\n",
      "Epoch [143/200], Loss: 0.3138\n",
      "Validation Loss: 0.3777, Accuracy: 90.91%\n",
      "Epoch [144/200], Loss: 0.3136\n",
      "Validation Loss: 0.3762, Accuracy: 90.91%\n",
      "Epoch [145/200], Loss: 0.3136\n",
      "Validation Loss: 0.3779, Accuracy: 90.91%\n",
      "Epoch [146/200], Loss: 0.3136\n",
      "Validation Loss: 0.3776, Accuracy: 90.91%\n",
      "Epoch [147/200], Loss: 0.3139\n",
      "Validation Loss: 0.3785, Accuracy: 90.91%\n",
      "Epoch [148/200], Loss: 0.3136\n",
      "Validation Loss: 0.3767, Accuracy: 90.91%\n",
      "Epoch [149/200], Loss: 0.3141\n",
      "Validation Loss: 0.3775, Accuracy: 90.91%\n",
      "Epoch [150/200], Loss: 0.3137\n",
      "Validation Loss: 0.3756, Accuracy: 90.91%\n",
      "Epoch [151/200], Loss: 0.3137\n",
      "Validation Loss: 0.3751, Accuracy: 90.91%\n",
      "Epoch [152/200], Loss: 0.3135\n",
      "Validation Loss: 0.3735, Accuracy: 90.91%\n",
      "Epoch [153/200], Loss: 0.3136\n",
      "Validation Loss: 0.3687, Accuracy: 90.91%\n",
      "Epoch [154/200], Loss: 0.3136\n",
      "Validation Loss: 0.3689, Accuracy: 90.91%\n",
      "Epoch [155/200], Loss: 0.3151\n",
      "Validation Loss: 0.3807, Accuracy: 90.91%\n",
      "Epoch [156/200], Loss: 0.3137\n",
      "Validation Loss: 0.4165, Accuracy: 88.64%\n",
      "Epoch [157/200], Loss: 0.3155\n",
      "Validation Loss: 0.3946, Accuracy: 86.36%\n",
      "Epoch [158/200], Loss: 0.3143\n",
      "Validation Loss: 0.3676, Accuracy: 90.91%\n",
      "Epoch [159/200], Loss: 0.3140\n",
      "Validation Loss: 0.3644, Accuracy: 93.18%\n",
      "Epoch [160/200], Loss: 0.3137\n",
      "Validation Loss: 0.3636, Accuracy: 93.18%\n",
      "Epoch [161/200], Loss: 0.3137\n",
      "Validation Loss: 0.3668, Accuracy: 93.18%\n",
      "Epoch [162/200], Loss: 0.3144\n",
      "Validation Loss: 0.3638, Accuracy: 93.18%\n",
      "Epoch [163/200], Loss: 0.3135\n",
      "Validation Loss: 0.3655, Accuracy: 93.18%\n",
      "Epoch [164/200], Loss: 0.3141\n",
      "Validation Loss: 0.3684, Accuracy: 90.91%\n",
      "Epoch [165/200], Loss: 0.3136\n",
      "Validation Loss: 0.3733, Accuracy: 90.91%\n",
      "Epoch [166/200], Loss: 0.3137\n",
      "Validation Loss: 0.3751, Accuracy: 90.91%\n",
      "Epoch [167/200], Loss: 0.3136\n",
      "Validation Loss: 0.3713, Accuracy: 90.91%\n",
      "Epoch [168/200], Loss: 0.3137\n",
      "Validation Loss: 0.3694, Accuracy: 90.91%\n",
      "Epoch [169/200], Loss: 0.3136\n",
      "Validation Loss: 0.3650, Accuracy: 93.18%\n",
      "Epoch [170/200], Loss: 0.3137\n",
      "Validation Loss: 0.3658, Accuracy: 93.18%\n",
      "Epoch [171/200], Loss: 0.3136\n",
      "Validation Loss: 0.3680, Accuracy: 93.18%\n",
      "Epoch [172/200], Loss: 0.3137\n",
      "Validation Loss: 0.3713, Accuracy: 90.91%\n",
      "Epoch [173/200], Loss: 0.3136\n",
      "Validation Loss: 0.3755, Accuracy: 88.64%\n",
      "Epoch [174/200], Loss: 0.3137\n",
      "Validation Loss: 0.3797, Accuracy: 88.64%\n",
      "Epoch [175/200], Loss: 0.3135\n",
      "Validation Loss: 0.3738, Accuracy: 88.64%\n",
      "Epoch [176/200], Loss: 0.3136\n",
      "Validation Loss: 0.3729, Accuracy: 88.64%\n",
      "Epoch [177/200], Loss: 0.3136\n",
      "Validation Loss: 0.3716, Accuracy: 90.91%\n",
      "Epoch [178/200], Loss: 0.3145\n",
      "Validation Loss: 0.3760, Accuracy: 90.91%\n",
      "Epoch [179/200], Loss: 0.3135\n",
      "Validation Loss: 0.3743, Accuracy: 90.91%\n",
      "Epoch [180/200], Loss: 0.3135\n",
      "Validation Loss: 0.3727, Accuracy: 90.91%\n",
      "Epoch [181/200], Loss: 0.3136\n",
      "Validation Loss: 0.3727, Accuracy: 90.91%\n",
      "Epoch [182/200], Loss: 0.3134\n",
      "Validation Loss: 0.3728, Accuracy: 90.91%\n",
      "Epoch [183/200], Loss: 0.3140\n",
      "Validation Loss: 0.3722, Accuracy: 90.91%\n",
      "Epoch [184/200], Loss: 0.3135\n",
      "Validation Loss: 0.3665, Accuracy: 90.91%\n",
      "Epoch [185/200], Loss: 0.3137\n",
      "Validation Loss: 0.3657, Accuracy: 90.91%\n",
      "Epoch [186/200], Loss: 0.3135\n",
      "Validation Loss: 0.3642, Accuracy: 93.18%\n",
      "Epoch [187/200], Loss: 0.3135\n",
      "Validation Loss: 0.3659, Accuracy: 90.91%\n",
      "Epoch [188/200], Loss: 0.3135\n",
      "Validation Loss: 0.3709, Accuracy: 90.91%\n",
      "Epoch [189/200], Loss: 0.3135\n",
      "Validation Loss: 0.3752, Accuracy: 90.91%\n",
      "Epoch [190/200], Loss: 0.3135\n",
      "Validation Loss: 0.3730, Accuracy: 90.91%\n",
      "Epoch [191/200], Loss: 0.3135\n",
      "Validation Loss: 0.3705, Accuracy: 90.91%\n",
      "Epoch [192/200], Loss: 0.3134\n",
      "Validation Loss: 0.3721, Accuracy: 90.91%\n",
      "Epoch [193/200], Loss: 0.3138\n",
      "Validation Loss: 0.3722, Accuracy: 90.91%\n",
      "Epoch [194/200], Loss: 0.3138\n",
      "Validation Loss: 0.3727, Accuracy: 90.91%\n",
      "Epoch [195/200], Loss: 0.3136\n",
      "Validation Loss: 0.3735, Accuracy: 90.91%\n",
      "Epoch [196/200], Loss: 0.3136\n",
      "Validation Loss: 0.3716, Accuracy: 90.91%\n",
      "Epoch [197/200], Loss: 0.3137\n",
      "Validation Loss: 0.3664, Accuracy: 93.18%\n",
      "Epoch [198/200], Loss: 0.3135\n",
      "Validation Loss: 0.3659, Accuracy: 93.18%\n",
      "Epoch [199/200], Loss: 0.3138\n",
      "Validation Loss: 0.3686, Accuracy: 90.91%\n",
      "Epoch [200/200], Loss: 0.3135\n",
      "Validation Loss: 0.3684, Accuracy: 90.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/06 16:24:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete and logged in MLflow.\n",
      "Precision: 0.6000000238418579\n",
      "Recall: 0.4285714328289032\n",
      "Accuracy: 0.8666666746139526\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'signature' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 99\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecall\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     96\u001b[0m mlflow\u001b[38;5;241m.\u001b[39msklearn\u001b[38;5;241m.\u001b[39mlog_model(\n\u001b[1;32m     97\u001b[0m     sk_model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     98\u001b[0m     artifact_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msklearn-model\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m---> 99\u001b[0m     signature\u001b[38;5;241m=\u001b[39m\u001b[43msignature\u001b[49m,\n\u001b[1;32m    100\u001b[0m     registered_model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msk-learn-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    101\u001b[0m )\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogged model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, RMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrmse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'signature' is not defined"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(nested=True):\n",
    "    # Log hyperparameters\n",
    "    mlflow.log_param(\"input_size\", input_size)\n",
    "    mlflow.log_param(\"hidden_size\", hidden_size)\n",
    "    mlflow.log_param(\"output_size\", output_size)\n",
    "    mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "    mlflow.log_param(\"batch_size\", batch_size)\n",
    "    mlflow.log_param(\"num_epochs\", num_epochs)\n",
    "    mlflow.log_param(\"n_features\", len(_X.columns))\n",
    "\n",
    "    mlflow.log_param(\"model_name\", 'batch_norm')\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_train_loss:.4f}\")\n",
    "        mlflow.log_metric(\"train_loss\", avg_train_loss, step=epoch)\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == targets).sum().item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = 100 * correct / total\n",
    "        print(f\"Validation Loss: {avg_val_loss:.4f}, Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "        mlflow.log_metric(\"val_loss\", avg_val_loss, step=epoch)\n",
    "        mlflow.log_metric(\"val_accuracy\", val_accuracy, step=epoch)\n",
    "\n",
    "    # Log the trained model\n",
    "    mlflow.pytorch.log_model(model, \"model\")\n",
    "\n",
    "    print(\"Model training complete and logged in MLflow.\")\n",
    "\n",
    "    # TEST PERFORMANCE ALANYSIS ------------------------------------------------------------------------------\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    # Pass the input tensor to the model\n",
    "    with torch.no_grad(): \n",
    "        predictions = model(X_test)\n",
    "    \n",
    "    y_pred = torch.argmax(predictions, dim=1)\n",
    "\n",
    "    y_true = y_test\n",
    "\n",
    "    # Calculate True Positives, False Positives, and False Negatives\n",
    "    tp = ((y_true == 1) & (y_pred == 1)).sum()  # True Positives\n",
    "    fp = ((y_true == 0) & (y_pred == 1)).sum()  # False Positives\n",
    "    fn = ((y_true == 1) & (y_pred == 0)).sum()  # False Negatives\n",
    "    tn = ((y_true == 0) & (y_pred == 0)).sum()  # True Negatives\n",
    "    \n",
    "    # Precision and Recall\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    \n",
    "    # Accuracy\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    \n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    \n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        artifact_path=\"sklearn-model\",\n",
    "        signature=signature,\n",
    "        registered_model_name=f\"sk-learn-{model_name}\",\n",
    "    )\n",
    "    \n",
    "    print(f\"Logged model: {model.__class__.__name__}, RMSE: {rmse}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead0ed91-f403-49ad-a528-68203dd87dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f358f8e8-41c5-4ad6-a1f9-03e6084cee8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset_indexes = _y_test.index\n",
    "\n",
    "y_pred_np = y_pred.numpy()\n",
    "\n",
    "true_positive = _y_test.reset_index().loc[(_y_test.reset_index()['mvp'] == 1) & (y_pred_np == 1)]\n",
    "false_positive = _y_test.reset_index().loc[(_y_test.reset_index()['mvp'] == 0) & (y_pred_np == 1)]\n",
    "false_negative = _y_test.reset_index().loc[(_y_test.reset_index()['mvp'] == 1) & (y_pred_np == 0)]\n",
    "true_negative = _y_test.reset_index().loc[(_y_test.reset_index()['mvp'] == 0) & (y_pred_np == 0)]\n",
    "\n",
    "# print(f\"true_positive:\\n {true_positive}\")\n",
    "# print(f\"false_positive:\\n {false_positive}\")\n",
    "# print(f\"false_negative:\\n {false_negative}\")\n",
    "\n",
    "cross_refs_path = \"/Users/cb/src/nba_mvp_ml/data/processed/by_season/fully_merged/player_index_mapping.csv\"\n",
    "cross_refs = pd.read_csv(cross_refs_path)\n",
    "\n",
    "print('\\nCorrectly predicted as MVP')\n",
    "for i in list(true_positive['index']):\n",
    "    player = cross_refs.iloc[i]['Player']\n",
    "    season = write_season(int(cross_refs.iloc[i]['SEASON_ID']))\n",
    "    \n",
    "    print(f'{season} {player}')\n",
    "\n",
    "print('\\nIncorrectly predicted as MVP')\n",
    "for i in list(false_positive['index']):\n",
    "    player = cross_refs.iloc[i]['Player']\n",
    "    season = write_season(int(cross_refs.iloc[i]['SEASON_ID']))\n",
    "    \n",
    "    print(f'{season} {player}')\n",
    "\n",
    "print('\\nIncorrectly predicted as non-MVP')\n",
    "for i in list(false_negative['index']):\n",
    "    player = cross_refs.iloc[i]['Player']\n",
    "    season = write_season(int(cross_refs.iloc[i]['SEASON_ID']))\n",
    "    \n",
    "    print(f'{season} {player}')\n",
    "\n",
    "print('\\nCorrectly predicted as non-MVP')\n",
    "for i in list(true_negative['index']):\n",
    "    player = cross_refs.iloc[i]['Player']\n",
    "    season = write_season(int(cross_refs.iloc[i]['SEASON_ID']))\n",
    "    \n",
    "    print(f'{season} {player}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9196fe-ecd6-4c2b-b059-76ba6c03a937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4a46d7-3d5c-4c32-b4f2-e1b6b435e430",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fb2db1-dfef-42fa-bc55-ba50a680a246",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
